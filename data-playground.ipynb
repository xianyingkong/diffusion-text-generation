{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10efb8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizerFast, BertTokenizerFast\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9a01d2-894f-4bc4-ab91-183cbd851842",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(102)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8866fb8b-f69f-46cc-9410-3b78fb0ff50c",
   "metadata": {},
   "source": [
    "# Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eae23cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/source/shakespeare.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93894566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataline</th>\n",
       "      <th>Play</th>\n",
       "      <th>PlayerLinenumber</th>\n",
       "      <th>ActSceneLine</th>\n",
       "      <th>Player</th>\n",
       "      <th>PlayerLine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACT I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SCENE I. London. The palace.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enter KING HENRY, LORD JOHN OF LANCASTER, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>So shaken as we are, so wan with care,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>Find we a time for frighted peace to pant,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataline      Play  PlayerLinenumber ActSceneLine         Player  \\\n",
       "0         1  Henry IV               NaN          NaN            NaN   \n",
       "1         2  Henry IV               NaN          NaN            NaN   \n",
       "2         3  Henry IV               NaN          NaN            NaN   \n",
       "3         4  Henry IV               1.0        1.1.1  KING HENRY IV   \n",
       "4         5  Henry IV               1.0        1.1.2  KING HENRY IV   \n",
       "\n",
       "                                          PlayerLine  \n",
       "0                                              ACT I  \n",
       "1                       SCENE I. London. The palace.  \n",
       "2  Enter KING HENRY, LORD JOHN OF LANCASTER, the ...  \n",
       "3             So shaken as we are, so wan with care,  \n",
       "4         Find we a time for frighted peace to pant,  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afcc48c4-6697-41e9-bd4e-391f5f074912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Play'].str.lower().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34af8bd7-4263-471f-8aeb-20bd2d1dac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Player'].str.lower().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b79b708c-c7e0-400f-a338-d9dfebc262b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# french characters: alencon, alice, king of france, katharine, dauphin\n",
    "# french speaking characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "956711ee-a133-4f3b-a440-902196514595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['Player'].str.lower() == 'katharine']\n",
    "# maybe could remove the whole of Henry V since that is where most french lines are found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4bf1750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Play</th>\n",
       "      <th>PlayerLinenumber</th>\n",
       "      <th>PlayerLine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>So shaken as we are, so wan with care,Find we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>2.0</td>\n",
       "      <td>My liege, this haste was hot in question,And m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>3.0</td>\n",
       "      <td>It seems then that the tidings of this broilBr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This match'd with other did, my gracious lord,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Here is a dear, a true industrious friend,Sir ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>194.0</td>\n",
       "      <td>Nothing but papers, my lord.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>195.0</td>\n",
       "      <td>Let's see what they be: read them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>196.0</td>\n",
       "      <td>[Reads]  Item, A capon,. . 2s. 2d.Item, Sauce,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>197.0</td>\n",
       "      <td>O monstrous! but one half-penny-worth of bread...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>198.0</td>\n",
       "      <td>Good morrow, good my lord.ACT IIISCENE I. Bang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Play  PlayerLinenumber  \\\n",
       "0    Henry IV               1.0   \n",
       "1    Henry IV               2.0   \n",
       "2    Henry IV               3.0   \n",
       "3    Henry IV               4.0   \n",
       "4    Henry IV               5.0   \n",
       "..        ...               ...   \n",
       "193  Henry IV             194.0   \n",
       "194  Henry IV             195.0   \n",
       "195  Henry IV             196.0   \n",
       "196  Henry IV             197.0   \n",
       "197  Henry IV             198.0   \n",
       "\n",
       "                                            PlayerLine  \n",
       "0    So shaken as we are, so wan with care,Find we ...  \n",
       "1    My liege, this haste was hot in question,And m...  \n",
       "2    It seems then that the tidings of this broilBr...  \n",
       "3    This match'd with other did, my gracious lord,...  \n",
       "4    Here is a dear, a true industrious friend,Sir ...  \n",
       "..                                                 ...  \n",
       "193                       Nothing but papers, my lord.  \n",
       "194                 Let's see what they be: read them.  \n",
       "195  [Reads]  Item, A capon,. . 2s. 2d.Item, Sauce,...  \n",
       "196  O monstrous! but one half-penny-worth of bread...  \n",
       "197  Good morrow, good my lord.ACT IIISCENE I. Bang...  \n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Play'] == 'Henry IV'].groupby(['Play', 'PlayerLinenumber']).agg(PlayerLine=('PlayerLine', np.sum)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70a2de6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActSceneLine</th>\n",
       "      <th>Player</th>\n",
       "      <th>PlayerLine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>So shaken as we are, so wan with care,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1.2</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>Find we a time for frighted peace to pant,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.1.3</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>And breathe short-winded accents of new broils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.1.4</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>To be commenced in strands afar remote.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.1.5</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>No more the thirsty entrance of this soil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ActSceneLine         Player                                      PlayerLine\n",
       "3        1.1.1  KING HENRY IV          So shaken as we are, so wan with care,\n",
       "4        1.1.2  KING HENRY IV      Find we a time for frighted peace to pant,\n",
       "5        1.1.3  KING HENRY IV  And breathe short-winded accents of new broils\n",
       "6        1.1.4  KING HENRY IV         To be commenced in strands afar remote.\n",
       "7        1.1.5  KING HENRY IV       No more the thirsty entrance of this soil"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove = df[(df['Player'].notna()) & (df[\"PlayerLine\"]!='Exeunt')]\n",
    "data = remove[['ActSceneLine', \"Player\", \"PlayerLine\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c740f7-a4a3-4a21-b31e-30923529f64c",
   "metadata": {},
   "source": [
    "# Preprocessing Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75565b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShakespeareData:\n",
    "    def __init__(self, filepath='data/source/shakespeare.csv'):        \n",
    "        data = pd.read_csv(filepath)\n",
    "        self.data = self.clean(data) \n",
    "    \n",
    "    def clean(self, data):\n",
    "        repl = {\n",
    "            '@\\w*': ' ', \n",
    "            '&amp;' : 'and',\n",
    "            '\\su\\s':' you ', \n",
    "            '&#\\w*;': ' ', \n",
    "            '#':' ', \n",
    "            '\\s2\\s': 'two', \n",
    "            \"ð[^ ]*\": ' ' ,\n",
    "            \"â[^ ]*\": ' ',\n",
    "            \"(dont)|(don't)\": 'do not', \n",
    "            \"(cant)|(can't)\": \"can not\",\n",
    "            \"(yous)|(you's)\": \"you is\", \n",
    "            \"(yous)|(you's)\": \"you is\", \n",
    "            \"(youve)|(you've)\": \"you have\", \n",
    "            \"(doesnt)|(doesn't)\": 'does not', \n",
    "            \"(wont)|(won't)\": 'will not', \n",
    "            \"honour\": 'honor',\n",
    "            \"durst\": 'dare',\n",
    "            \"wast\": 'was',\n",
    "            \"curst\": 'cursed',\n",
    "            \"blest\": 'blessed',\n",
    "            \"crost\": 'crossed',\n",
    "            \"accurst\": 'accursed',\n",
    "            \"o'ver\": 'over',\n",
    "            \"\\'tis'\": 'this',\n",
    "            \"[0-9]+\\.*[0-9%]+\\w*\" : \"NUMBER\",\n",
    "            '\\\\n\\.':' ' ,\n",
    "            '\\\\n':' ',\n",
    "            \"\\.{2,}\": '.', \n",
    "            \"!{2,}\":'!', \n",
    "            \"\\?{2,}\":'?', \n",
    "#             'ing[^a-z]':' ', \n",
    "#             'ed[^a-z]': ' ', \n",
    "            '_':\" \",\n",
    "            ' +': ' ', \n",
    "            '\\-{2,}': ' ', \n",
    "            '\\-': '',\n",
    "            '\\:': '',\n",
    "            \"\\'d\": \"ed\"}\n",
    "\n",
    "        data = data[(data['Player'].notna()) & (data[\"PlayerLine\"]!='Exeunt') & (data[\"Play\"]!='Henry V')]\n",
    "        data = data[['ActSceneLine', \"Player\", \"PlayerLine\", \"Play\"]]\n",
    "        cleaned = data['PlayerLine'].apply(lambda x: x.strip().lower())\n",
    "        cleaned = cleaned.replace(repl, regex=True)\n",
    "        cleaned_data = data.assign(text = cleaned)\n",
    "        return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aaced27-12ab-4ca7-81ee-9394380f0978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(data_col, tokenizer_config='bert-base-uncased', max_tokens=50000):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_config) # Bert will be the base tokenizer\n",
    "    lines_iter = iter(data_col) # Most likely not needed, already in list\n",
    "\n",
    "    # Creates new tokenizer with our vocabulary set\n",
    "    return tokenizer.train_new_from_iterator(lines_iter, max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da7308df-27a4-4321-9b91-2d9f9e4bd25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_src_trg_dataset(text_col):\n",
    "    data = []\n",
    "    \n",
    "#     for i in range(len(text_col)-1):\n",
    "#         dictionary = {}\n",
    "#         dictionary[\"src\"] = text_col.iloc[i]\n",
    "#         dictionary[\"trg\"] = text_col.iloc[i+1]\n",
    "#         data.append(dictionary)\n",
    "\n",
    "    for i in range(len(text_col)-5):\n",
    "        dictionary = {}\n",
    "        dictionary[\"src\"] = (text_col.iloc[i] + \" \" + text_col.iloc[i+1] + \" \" + text_col.iloc[i+2]).strip()\n",
    "        dictionary[\"trg\"] = (text_col.iloc[i+3] + \" \" + text_col.iloc[i+4] + \" \" + text_col.iloc[i+5]).strip()\n",
    "        data.append(dictionary)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def save_src_trg_dataset(data, filename = 'data', folder_dir = ''):\n",
    "    fn = folder_dir + filename + '.jsonl'\n",
    "    with open(fn, 'w') as outfile:\n",
    "        for entry in data:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "def generate_and_save_dataset(data_text_column, filename= 'data', folder_dir= ''):\n",
    "    data = generate_src_trg_dataset(data_text_column)\n",
    "    save_src_trg_dataset(data, filename=filename, folder_dir=folder_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dd68604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('vocab_list.pickle', 'wb') as handle:\n",
    "#     pickle.dump(vocab.idx_word, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3dffb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_data = ShakespeareData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f653c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActSceneLine</th>\n",
       "      <th>Player</th>\n",
       "      <th>PlayerLine</th>\n",
       "      <th>Play</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>So shaken as we are, so wan with care,</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>so shaken as we are, so wan with care,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1.2</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>Find we a time for frighted peace to pant,</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>find we a time for frighted peace to pant,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.1.3</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>And breathe short-winded accents of new broils</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>and breathe shortwinded accents of new broils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.1.4</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>To be commenced in strands afar remote.</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>to be commenced in strands afar remote.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.1.5</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>No more the thirsty entrance of this soil</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>no more the thirsty entrance of this soil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ActSceneLine         Player                                      PlayerLine  \\\n",
       "3        1.1.1  KING HENRY IV          So shaken as we are, so wan with care,   \n",
       "4        1.1.2  KING HENRY IV      Find we a time for frighted peace to pant,   \n",
       "5        1.1.3  KING HENRY IV  And breathe short-winded accents of new broils   \n",
       "6        1.1.4  KING HENRY IV         To be commenced in strands afar remote.   \n",
       "7        1.1.5  KING HENRY IV       No more the thirsty entrance of this soil   \n",
       "\n",
       "       Play                                           text  \n",
       "3  Henry IV         so shaken as we are, so wan with care,  \n",
       "4  Henry IV     find we a time for frighted peace to pant,  \n",
       "5  Henry IV  and breathe shortwinded accents of new broils  \n",
       "6  Henry IV        to be commenced in strands afar remote.  \n",
       "7  Henry IV      no more the thirsty entrance of this soil  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_data.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c1c2bc2-f64d-4c35-8ce1-09227653ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plays = shakespeare_data.data.Play.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4671ef0-de7c-4771-9e09-c651d658c91d",
   "metadata": {},
   "source": [
    "### Preparing train/test Shakespeare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c09414bf-bc6d-488a-8ff7-d5df38db1879",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = []\n",
    "for play in all_plays:\n",
    "    text_col = shakespeare_data.data[shakespeare_data.data['Play'] == play]['text']\n",
    "    processed_data += generate_src_trg_dataset(text_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbbed31d-794c-4d82-9580-faa20fb0a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(processed_data) # in-place shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0419bde-52f6-489b-8ad3-87a971166c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107284"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(processed_data)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "becf3dc3-9283-47b4-99c3-2e43f9a9d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff = int(n*0.9)\n",
    "cutoff = -20\n",
    "ss_train_data, ss_test_data = processed_data[:cutoff], processed_data[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3906803-830c-46e1-9f7b-e43543c70e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_src_trg_dataset(ss_train_data, filename= 'train', folder_dir= 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30838a59-aa89-4a49-96f5-8722503b9abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_src_trg_dataset(ss_test_data, filename= 'test', folder_dir= 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "534b0a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Tokenizer contains vocab size 33747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['so', 'shaken', 'as', 'we', 'are', ',', 'so', 'wan', 'with', 'care', ',']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just for sanity check\n",
    "tokenizer = create_tokenizer(shakespeare_data.data.text)\n",
    "print(f'Tokenizer contains vocab size {tokenizer.vocab_size}')\n",
    "tokenizer.tokenize(shakespeare_data.data.text.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0dcc607e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(tokenizer, PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e7e99b66-35db-4e17-8738-e50bb940d826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='bert-base-uncased', vocab_size=33747, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "113efd31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('shakespeare-tokenizer-bert/plays/tokenizer_config.json',\n",
       " 'shakespeare-tokenizer-bert/plays/special_tokens_map.json',\n",
       " 'shakespeare-tokenizer-bert/plays/vocab.txt',\n",
       " 'shakespeare-tokenizer-bert/plays/added_tokens.json',\n",
       " 'shakespeare-tokenizer-bert/plays/tokenizer.json')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save tokenizer\n",
    "tokenizer_save_path = 'shakespeare-tokenizer-bert/plays'\n",
    "tokenizer.save_pretrained(tokenizer_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1030d0-04cd-4538-aeda-688b5c8fa1b0",
   "metadata": {},
   "source": [
    "## Creating CC tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab9af3ad-9676-4792-932c-bc8e75d9b8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_train_data_dir='data/commonsense/train.jsonl'\n",
    "comb_test_data_dir='data/commonsense/test.jsonl'\n",
    "\n",
    "comb_data = []\n",
    "\n",
    "with open(comb_train_data_dir, 'r') as f_reader:\n",
    "    for row in f_reader:\n",
    "        comb_data.append(json.loads(row))\n",
    "        \n",
    "with open(comb_test_data_dir, 'r') as f_reader:\n",
    "    for row in f_reader:\n",
    "        comb_data.append(json.loads(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de4e473a-44e7-4156-9c14-ba17ba781054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'src': 'jesus , what kind of concerts do you go to where people sucker punch you for being born tall ?',\n",
       "  'trg': 'the kind that allow bitter short people in . so basically all of them .'},\n",
       " 3392137)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_data[0], len(comb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1406f7b4-6de4-4698-b55a-c684848212b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_lines = []\n",
    "for line in comb_data:\n",
    "    l = line['src'] + \" \" + line['trg']\n",
    "    merged_lines.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f6ee73c-4b19-4e65-a83b-adf1900c0107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased') # Bert will be the base tokenizer\n",
    "lines_iter = iter(merged_lines) # Most likely not needed, already in list\n",
    "\n",
    "# Creates new tokenizer with our vocabulary set\n",
    "comb_tokenizer = tokenizer.train_new_from_iterator(lines_iter, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8206becc-fda2-4e3e-aee0-cf61f6a7081e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='bert-base-uncased', vocab_size=49959, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b305c915-21a8-4f83-b0a2-f1d95175f7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('commonsense-tokenizer-bert/tokenizer_config.json',\n",
       " 'commonsense-tokenizer-bert/special_tokens_map.json',\n",
       " 'commonsense-tokenizer-bert/vocab.txt',\n",
       " 'commonsense-tokenizer-bert/added_tokens.json',\n",
       " 'commonsense-tokenizer-bert/tokenizer.json')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_tokenizer.save_pretrained(\"commonsense-tokenizer-bert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a21b6c-7849-48a4-9494-4cf04e61d616",
   "metadata": {},
   "source": [
    "# Preparing Shakespeare train/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4702802e-d10d-40b7-80a0-bec5ead68c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_all_data_dir='data/all.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e79c1d9b-a1fe-4158-b504-9785123c5944",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_all_data = []\n",
    "with open(ss_all_data_dir, 'r') as f_reader:\n",
    "    for row in f_reader:\n",
    "        ss_all_data.append(json.loads(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b9feb99-94a9-4227-9654-bb25ca71f303",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(ss_all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f29f4f77-bda2-4659-bb21-9309fd5ce88e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss_train_data = ss_all_data[:-20]\n",
    "ss_test_data = ss_all_data[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "747273fc-9776-4b9a-bcc6-8da35db802e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 110814)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ss_test_data), len(ss_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a267a238-b9c7-46d4-b2f3-f5dbc15ba598",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_src_trg_dataset(ss_train_data, filename= 'train', folder_dir= 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "675aa32d-86c6-471e-b59c-409b482e13dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_src_trg_dataset(ss_test_data, filename= 'test', folder_dir= 'data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaefc9b-a646-4792-ad97-8b7113e8c4b5",
   "metadata": {},
   "source": [
    "# Preparing combined dataset (Commonsense Dialogue & Shakespeare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1a36a0f8-9b33-4f07-b467-3585c48942e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_train_data_dir='data/commonsense/train.jsonl'\n",
    "ss_train_data_dir='data/shakespeare/train.jsonl'\n",
    "cc_test_data_dir='data/commonsense/test.jsonl'\n",
    "ss_test_data_dir='data/shakespeare/test.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb4c27fa-d8f5-4aff-b3ed-5307a35cced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_train_data = []\n",
    "with open(cc_train_data_dir, 'r') as f_reader:\n",
    "    for row in f_reader:\n",
    "        cc_train_data.append(json.loads(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "22b8a81e-9d34-4145-8157-0cc9a402742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_test_data = []\n",
    "with open(cc_test_data_dir, 'r') as f_reader:\n",
    "    for row in f_reader:\n",
    "        cc_test_data.append(json.loads(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d9008e5-66d1-48f2-9ea2-ad38267a4fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_train_data = []\n",
    "with open(ss_train_data_dir, 'r') as f_reader:\n",
    "    for row in f_reader:\n",
    "        ss_train_data.append(json.loads(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6a514b02-efba-425f-96ec-5d6be3ad23b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_test_data = []\n",
    "with open(ss_test_data_dir, 'r') as f_reader:\n",
    "    for row in f_reader:\n",
    "        ss_test_data.append(json.loads(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "93af9e29-a656-44c6-ac95-3a58511b5e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3382137, 99754, 10000, 11084)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cc_train_data), len(ss_train_data), len(cc_test_data), len(ss_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1e5fb25-89eb-43a6-9c80-d27732db35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(cc_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0365aca5-b03a-48ee-a3aa-d49e82c5d0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_data = cc_train_data[:1_000_000] + ss_train_data\n",
    "combined_test_data = cc_test_data[-10:] + ss_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e78720d-44bb-484e-8772-407a93371af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1110818, 30)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(combined_train_data)\n",
    "random.shuffle(combined_test_data)\n",
    "len(combined_train_data), len(combined_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3558649f-d080-483d-83ac-cdf341f3b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_src_trg_dataset(combined_test_data, filename= 'test', folder_dir= 'data/combined/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fcd03953-748f-46ed-81f6-14c122e1e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_src_trg_dataset(combined_train_data, filename= 'train', folder_dir= 'data/combined/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61b3336-b0d3-4641-aa76-95b86ccc472b",
   "metadata": {},
   "source": [
    "# Preparing small combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58df2a18-9670-4aac-afe9-7bb18b593cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_train_data_dir='data/combined/train.jsonl'\n",
    "comb_test_data_dir='data/combined/test.jsonl'\n",
    "\n",
    "comb_train_data = []\n",
    "comb_test_data = []\n",
    "\n",
    "with open(comb_train_data_dir, 'r') as f_reader:\n",
    "    for row in f_reader:\n",
    "        comb_train_data.append(json.loads(row))\n",
    "        \n",
    "with open(comb_test_data_dir, 'r') as f_reader:\n",
    "    for row in f_reader:\n",
    "        comb_test_data.append(json.loads(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e70b0614-6cf3-4ee0-aec0-16dae53d07a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_data=comb_train_data[:100]\n",
    "combined_test_data=comb_test_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23202b8c-3fa1-44fb-9c37-aca27d124a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_src_trg_dataset(combined_test_data, filename= 'test', folder_dir= 'data/combined/small/')\n",
    "save_src_trg_dataset(combined_train_data, filename= 'train', folder_dir= 'data/combined/small/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc9b1cc-7057-438b-b406-ccc446cd7d7c",
   "metadata": {},
   "source": [
    "# Preparing tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8f8df37b-9c70-4310-ada2-73bd76b14d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_config = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "55a6f00b-5853-49a6-ad6e-ddbf35886f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "33e6943d-8d4b-42d2-8ee8-b28cb1884b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_tokenizer = BertTokenizerFast('shakespeare-tokenizer-bert/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "db4c5725-f595-440b-91d0-f0bd7d54c9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokens = set(ss_tokenizer.vocab.keys())-set(tokenizer.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "28d6e85d-8f07-4c47-acab-d41ad96db801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19044"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_tokens) # these tokens will be added to bert tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cb6182-ea97-4d6e-a420-a95e1517bc8c",
   "metadata": {},
   "source": [
    "# Introducing Sonnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "78d13125-42ee-4899-93a8-05fc448b4f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/source/sonnets.txt', 'r') as f:\n",
    "    data = f.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d20d4409-781d-433e-a7a9-3f65aed16da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " \"from fairest creatures we desire increase,\\nthat thereby beauty's rose might never die,\\nbut as the riper should by time decease,\\nhis tender heir might bear his memory:\\nbut thou contracted to thine own bright eyes,\\nfeed'st thy light's flame with self-substantial fuel,\\nmaking a famine where abundance lies,\\nthy self thy foe, to thy sweet self too cruel:\\nthou that art now the world's fresh ornament,\\nand only herald to the gaudy spring,\\nwithin thine own bud buriest thy content,\\nand tender churl mak'st waste in niggarding:\\n  pity the world, or else this glutton be,\\n  to eat the world's due, by the grave and thee.\",\n",
       " 'ii',\n",
       " \"when forty winters shall besiege thy brow,\\nand dig deep trenches in thy beauty's field,\\nthy youth's proud livery so gazed on now,\\nwill be a tatter'd weed of small worth held: \\nthen being asked, where all thy beauty lies,\\nwhere all the treasure of thy lusty days; \\nto say, within thine own deep sunken eyes,\\nwere an all-eating shame, and thriftless praise.\\nhow much more praise deserv'd thy beauty's use,\\nif thou couldst answer 'this fair child of mine\\nshall sum my count, and make my old excuse,'\\nproving his beauty by succession thine!\\n  this were to be new made when thou art old,\\n  and see thy blood warm when thou feel'st it cold.\"]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonnets = data.split('\\n\\n')\n",
    "sonnets[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b2e15d39-2e75-4ddf-8706-99bf7194de17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnets_num = []\n",
    "sonnets_text = []\n",
    "for i in range(len(sonnets)):\n",
    "    if len(sonnets[i]) <= 10:\n",
    "        sonnets_num.append(sonnets[i])\n",
    "    else:\n",
    "        sonnets_text.append(sonnets[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "54b4bc52-c237-4491-b5dd-8b5c5a983aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnets_cleaned = []\n",
    "for s in sonnets_text:\n",
    "    # Shakespeare's sonnets are made of 3 quatrains (4-line stanza) and last 2 lines belong together\n",
    "    curr = s.split('\\n')\n",
    "    curr = [i.strip().replace(\"'d\", \"ed\") for i in curr]\n",
    "    q1 = curr[:4]\n",
    "    q2 = curr[4:8]\n",
    "    q3 = curr[8:12]\n",
    "    c1 = curr[12:]\n",
    "    sonnets_cleaned.append([' '.join(q1), ' '.join(q2), ' '.join(q3), ' '.join(c1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "02ff35af-01d1-4e9a-a97e-60442306551d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"from fairest creatures we desire increase, that thereby beauty's rose might never die, but as the riper should by time decease, his tender heir might bear his memory:\",\n",
       "  \"but thou contracted to thine own bright eyes, feed'st thy light's flame with self-substantial fuel, making a famine where abundance lies, thy self thy foe, to thy sweet self too cruel:\",\n",
       "  \"thou that art now the world's fresh ornament, and only herald to the gaudy spring, within thine own bud buriest thy content, and tender churl mak'st waste in niggarding:\",\n",
       "  \"pity the world, or else this glutton be, to eat the world's due, by the grave and thee.\"],\n",
       " [\"when forty winters shall besiege thy brow, and dig deep trenches in thy beauty's field, thy youth's proud livery so gazed on now, will be a tattered weed of small worth held:\",\n",
       "  'then being asked, where all thy beauty lies, where all the treasure of thy lusty days; to say, within thine own deep sunken eyes, were an all-eating shame, and thriftless praise.',\n",
       "  \"how much more praise deserved thy beauty's use, if thou couldst answer 'this fair child of mine shall sum my count, and make my old excuse,' proving his beauty by succession thine!\",\n",
       "  \"this were to be new made when thou art old, and see thy blood warm when thou feel'st it cold.\"]]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonnets_cleaned[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "04824775-983e-40e0-99b1-a0ae89cf6d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnets_src_trg_data = []\n",
    "for s in sonnets_cleaned:\n",
    "    for i in range(3):\n",
    "        dictionary = {}\n",
    "        dictionary[\"src\"] = s[i].strip()\n",
    "        dictionary[\"trg\"] = s[i+1].strip()\n",
    "        sonnets_src_trg_data.append(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d788cb9a-0693-4f29-b43d-79586c78db7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'src': \"from fairest creatures we desire increase, that thereby beauty's rose might never die, but as the riper should by time decease, his tender heir might bear his memory:\",\n",
       "  'trg': \"but thou contracted to thine own bright eyes, feed'st thy light's flame with self-substantial fuel, making a famine where abundance lies, thy self thy foe, to thy sweet self too cruel:\"},\n",
       " {'src': \"but thou contracted to thine own bright eyes, feed'st thy light's flame with self-substantial fuel, making a famine where abundance lies, thy self thy foe, to thy sweet self too cruel:\",\n",
       "  'trg': \"thou that art now the world's fresh ornament, and only herald to the gaudy spring, within thine own bud buriest thy content, and tender churl mak'st waste in niggarding:\"},\n",
       " {'src': \"thou that art now the world's fresh ornament, and only herald to the gaudy spring, within thine own bud buriest thy content, and tender churl mak'st waste in niggarding:\",\n",
       "  'trg': \"pity the world, or else this glutton be, to eat the world's due, by the grave and thee.\"}]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonnets_src_trg_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f452cbd0-386d-4c49-a8b7-0c6b4c326f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sonnets_src_trg_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86622da0-50c6-422b-9f2a-5c6c5409a448",
   "metadata": {},
   "source": [
    "## Combining Sonnets with Plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "058381b2-b129-4b3f-a75c-dc2a08ba5436",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = []\n",
    "for play in all_plays:\n",
    "    text_col = shakespeare_data.data[shakespeare_data.data['Play'] == play]['text']\n",
    "    processed_data += generate_src_trg_dataset(text_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "90b2c742-8a87-498a-aca2-d001a09c8c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data += sonnets_src_trg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4132d775-e8f7-4dda-9799-411e641a618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(processed_data) # in-place shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a64e5bbe-357f-4bac-beb9-227c8d80c52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107746"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(processed_data)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b6a684e3-2e20-464b-9e86-b31fcad9fd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff = int(n*0.9)\n",
    "cutoff = -20\n",
    "ss_train_data, ss_test_data = processed_data[:cutoff], processed_data[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cb246979-10bd-4639-9e90-e64676aac276",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_src_trg_dataset(ss_train_data, filename= 'train', folder_dir= 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "94abac1a-3c68-42f9-815a-2c88d9c526a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_src_trg_dataset(ss_test_data, filename= 'test', folder_dir= 'data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b10e2c-ca61-4887-a464-1feaf84331f8",
   "metadata": {},
   "source": [
    "## Creating Sonnets tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "802f851b-4508-41ca-ad87-b947bbbcc1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sonnets_tokenizer = create_tokenizer(np.array(sonnets_cleaned).flatten().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f22d0118-2c0b-4a9f-9832-f3c2513c08e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('shakespeare-tokenizer-bert/sonnets/tokenizer_config.json',\n",
       " 'shakespeare-tokenizer-bert/sonnets/special_tokens_map.json',\n",
       " 'shakespeare-tokenizer-bert/sonnets/vocab.txt',\n",
       " 'shakespeare-tokenizer-bert/sonnets/added_tokens.json',\n",
       " 'shakespeare-tokenizer-bert/sonnets/tokenizer.json')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_save_path = 'shakespeare-tokenizer-bert/sonnets'\n",
    "sonnets_tokenizer.save_pretrained(tokenizer_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
