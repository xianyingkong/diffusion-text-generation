{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99f2f837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 15:16:46.543338: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-26 15:16:46.543387: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-26 15:16:46.552176: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-26 15:16:46.563268: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-26 15:16:47.899407: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tokenizer import load_tokenizer\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "44282b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model_fp = f'models/better/model_best_epoch_22400_min_val_loss_0.027400000020861626.pkl' # warm up + llrd, dropout 0.1, bs 20\n",
    "# best_model_fp = 'models/better/model_best_epoch_22400_min_val_loss_0.028599999845027924.pkl' # warm up + llrd, dropout 0.2, bs 20\n",
    "# best_model_fp = 'models/better/model_best_epoch_20600_min_val_loss_0.028699999675154686.pkl' # dropout 0.2, bs 15\n",
    "best_model_fp = 'models/better/model_best_epoch_20600_min_val_loss_0.026000000536441803.pkl' # warm up, dropout 0.1, bs 15\n",
    "with open(best_model_fp, 'rb') as handle:\n",
    "    best_model = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a70ca5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in best_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50efe7ca",
   "metadata": {},
   "source": [
    "# Comparing diffusion models (by # steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1ddb61eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gaussian_diffusion import get_named_beta_schedule, SpacedDiffusion\n",
    "from tokenizer import load_tokenizer\n",
    "from transformers import set_seed\n",
    "from sampling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "586d92d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_schedule='sqrt'\n",
    "predict_xstart=True\n",
    "rescale_timesteps=True\n",
    "regular_data_dir='data'\n",
    "seed=102\n",
    "config_name='bert-base-uncased'\n",
    "\n",
    "set_seed(seed)\n",
    "tokenizer = load_tokenizer('shakespeare_plays', config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1f589b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_100 = SpacedDiffusion(\n",
    "    betas=get_named_beta_schedule(noise_schedule, 100),\n",
    "    rescale_timesteps=rescale_timesteps,\n",
    "    predict_xstart=predict_xstart,\n",
    ")\n",
    "\n",
    "diffusion_500 = SpacedDiffusion(\n",
    "    betas=get_named_beta_schedule(noise_schedule, 500),\n",
    "    rescale_timesteps=rescale_timesteps,\n",
    "    predict_xstart=predict_xstart,\n",
    ")\n",
    "\n",
    "diffusion_1000 = SpacedDiffusion(\n",
    "    betas=get_named_beta_schedule(noise_schedule, 1000),\n",
    "    rescale_timesteps=rescale_timesteps,\n",
    "    predict_xstart=predict_xstart,\n",
    ")\n",
    "\n",
    "diffusion_2000 = SpacedDiffusion(\n",
    "    betas=get_named_beta_schedule(noise_schedule, 2000),\n",
    "    rescale_timesteps=rescale_timesteps,\n",
    "    predict_xstart=predict_xstart,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491b097f",
   "metadata": {},
   "source": [
    "### With 100 diffusion steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "66803d50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## \n",
      "Loading text data...\n",
      "############################## \n",
      "Loading dataset from data...\n",
      "### Loading from the custom TEST set...\n",
      "### Data samples...\n",
      " ['life has meanings.', 'call her forth to me.'] ['', '']\n",
      "RAM used: 2454.54 MB\n",
      "This is raw_datasets:  Dataset({\n",
      "    features: ['src', 'trg'],\n",
      "    num_rows: 5\n",
      "})\n",
      "RAM used: 2454.54 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a4464cb3e547ecbd59be8d03d26e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=4):   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### tokenized_datasets Dataset({\n",
      "    features: ['input_id_x', 'input_id_y'],\n",
      "    num_rows: 5\n",
      "})\n",
      "### tokenized_datasets...example [2, 450, 778, 14764, 11, 3]\n",
      "RAM used: 2454.63 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd4e6588eb92460693f5e1b979132729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merge and mask:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 2454.66 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f98d6e03674878a5a653ffa3484671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "padding:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "    num_rows: 5\n",
      "}) padded dataset\n",
      "RAM used: 2454.71 MB\n",
      "RAM used: 2454.71 MB\n",
      "### End of reading iteration...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10788167f39483f8f5c81472c3a5b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover, word_lst_ref = sampling(best_model, \n",
    "                                                           diffusion_100, \n",
    "                                                           tokenizer, \n",
    "                                                           data_dir=regular_data_dir, \n",
    "                                                           batch_size=10, \n",
    "                                                           split='test_custom', \n",
    "                                                           seq_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "fe90e66d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[CLS] life has meanings. [SEP] [SEP]',\n",
       "  '[CLS] call her forth to me. [SEP] [SEP]',\n",
       "  '[CLS] what is your will? [SEP] [SEP]',\n",
       "  '[CLS] hark, fair sarah! [SEP] [SEP]',\n",
       "  \"[CLS] what dost thou have planned for the morrow's reprieve? [SEP] [SEP]\"],\n",
       " [\"[CLS]'i go worth at, me at, [SEP]\",\n",
       "  '[CLS] you, you,, thus i the with what her worth. [SEP]',\n",
       "  \"[CLS], you being have i so's s at them, have me the it. may name [SEP]\",\n",
       "  \"[CLS], with some, you s that your no on'[SEP]!\",\n",
       "  \"[CLS] he unto's then but do it thy is's worth. [SEP]\"])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318e9df5-0eda-4d16-9131-5a6c253b19c1",
   "metadata": {},
   "source": [
    "### With 500 diffusion steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0873c813-b621-4b88-9cb4-ad71efbc2db7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## \n",
      "Loading text data...\n",
      "############################## \n",
      "Loading dataset from data...\n",
      "### Loading from the custom TEST set...\n",
      "### Data samples...\n",
      " ['the meaning of life is', 'call her forth to me .'] ['', '']\n",
      "RAM used: 2454.05 MB\n",
      "This is raw_datasets:  Dataset({\n",
      "    features: ['src', 'trg'],\n",
      "    num_rows: 5\n",
      "})\n",
      "RAM used: 2454.05 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd657c424f2407d96733c44bb907301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=4):   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### tokenized_datasets Dataset({\n",
      "    features: ['input_id_x', 'input_id_y'],\n",
      "    num_rows: 5\n",
      "})\n",
      "### tokenized_datasets...example [2, 77, 2678, 93, 450, 120, 3]\n",
      "RAM used: 2454.08 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521a2ec6c3644a238a21f73beb89e4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merge and mask:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 2454.08 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a805f01dc82b47ed914c0784b0c95d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "padding:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "    num_rows: 5\n",
      "}) padded dataset\n",
      "RAM used: 2454.08 MB\n",
      "RAM used: 2454.08 MB\n",
      "### End of reading iteration...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56453e26d6548fb94598ba76d3c6ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover, word_lst_ref = sampling(best_model, \n",
    "                                                           diffusion_500, \n",
    "                                                           tokenizer, \n",
    "                                                           data_dir=regular_data_dir, \n",
    "                                                           batch_size=10, \n",
    "                                                           split='test_custom', \n",
    "                                                           seq_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "85395e1e-3170-44b2-9968-1efb55c0d4d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[CLS] the meaning of life is [SEP] [SEP]',\n",
       "  '[CLS] call her forth to me. [SEP] [SEP]',\n",
       "  '[CLS] what is your will? [SEP] [SEP]',\n",
       "  '[CLS] hark, fair sarah! [SEP] [SEP]',\n",
       "  \"[CLS] what dost thou have planned for the morrow's reprieve? [SEP] [SEP]\"],\n",
       " ['[CLS] night with have the had are him than thy of thy your though in,, of comes in, [SEP]',\n",
       "  \"[CLS] then'france,? hand men,. take [PAD]? [PAD] [PAD] [PAD] [SEP]\",\n",
       "  '[CLS] come the [SEP] is',\n",
       "  '[CLS] but master, our by great? and her the make worth! [SEP]',\n",
       "  '[CLS] no it is hast the have me night, s yourself above,, there from - - your [SEP]'])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5154696",
   "metadata": {},
   "source": [
    "### With 1000 diffusion steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fb88c719",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## \n",
      "Loading text data...\n",
      "############################## \n",
      "Loading dataset from data...\n",
      "### Loading from the custom TEST set...\n",
      "### Data samples...\n",
      " ['the meaning of life is', 'call her forth to me .'] ['', '']\n",
      "RAM used: 2453.98 MB\n",
      "This is raw_datasets:  Dataset({\n",
      "    features: ['src', 'trg'],\n",
      "    num_rows: 5\n",
      "})\n",
      "RAM used: 2453.98 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2be098970a04dd4bb92bea9ab148b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=4):   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### tokenized_datasets Dataset({\n",
      "    features: ['input_id_x', 'input_id_y'],\n",
      "    num_rows: 5\n",
      "})\n",
      "### tokenized_datasets...example [2, 77, 2678, 93, 450, 120, 3]\n",
      "RAM used: 2454.01 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbab69c55c2f49a0a4083c70fa14894e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merge and mask:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 2454.01 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3f8fc0b0db4e4b9d25277a8a94d7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "padding:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "    num_rows: 5\n",
      "}) padded dataset\n",
      "RAM used: 2454.01 MB\n",
      "RAM used: 2454.01 MB\n",
      "### End of reading iteration...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8566f0d5f1f34b7c8d9b7283ba8a6b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover, word_lst_ref = sampling(best_model, \n",
    "                                                           diffusion_1000, \n",
    "                                                           tokenizer, \n",
    "                                                           data_dir=regular_data_dir, \n",
    "                                                           batch_size=10, \n",
    "                                                           split='test_custom', \n",
    "                                                           seq_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "80bcd249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[CLS] the meaning of life is [SEP] [SEP]',\n",
       "  '[CLS] call her forth to me. [SEP] [SEP]',\n",
       "  '[CLS] what is your will? [SEP] [SEP]',\n",
       "  '[CLS] hark, fair sarah! [SEP] [SEP]',\n",
       "  \"[CLS] what dost thou have planned for the morrow's reprieve? [SEP] [SEP]\"],\n",
       " [\"[CLS] o, a i the some am, the'd and above? worth. [SEP]\",\n",
       "  \"[CLS] we d'i my,?'st [PAD]. [SEP]\",\n",
       "  \"[CLS] than these you,, thee myself, as what, why, how thy may s on to - this it, ', [SEP]\",\n",
       "  \"[CLS] now here shall, i no'thee master now this this s thou i call of come what.?'majesty thy as. [SEP]\",\n",
       "  \"[CLS] now, sir, lord'd queen. [SEP]\"])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81848646",
   "metadata": {},
   "source": [
    "### With 2000 diffusion steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c0924878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## \n",
      "Loading text data...\n",
      "############################## \n",
      "Loading dataset from data...\n",
      "### Loading from the custom TEST set...\n",
      "### Data samples...\n",
      " ['the meaning of life is', 'call her forth to me .'] ['', '']\n",
      "RAM used: 2454.07 MB\n",
      "This is raw_datasets:  Dataset({\n",
      "    features: ['src', 'trg'],\n",
      "    num_rows: 5\n",
      "})\n",
      "RAM used: 2454.07 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fbd89f76e3f40f38ffe80f0f1b26115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=4):   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### tokenized_datasets Dataset({\n",
      "    features: ['input_id_x', 'input_id_y'],\n",
      "    num_rows: 5\n",
      "})\n",
      "### tokenized_datasets...example [2, 77, 2678, 93, 450, 120, 3]\n",
      "RAM used: 2454.13 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567f1bfb56244317940d854f2f9eb60d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merge and mask:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 2454.16 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9b01474dc149c983c4c4c1463d19a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "padding:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "    num_rows: 5\n",
      "}) padded dataset\n",
      "RAM used: 2454.21 MB\n",
      "RAM used: 2454.21 MB\n",
      "### End of reading iteration...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66ab947d6a2462290fde8e4fd635120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover, word_lst_ref = sampling(best_model, \n",
    "                                                           diffusion_2000, \n",
    "                                                           tokenizer, \n",
    "                                                           data_dir=regular_data_dir, \n",
    "                                                           batch_size=10, \n",
    "                                                           split='test_custom', \n",
    "                                                           seq_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a934d91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[CLS] the meaning of life is [SEP] [SEP]',\n",
       "  '[CLS] call her forth to me. [SEP] [SEP]',\n",
       "  '[CLS] what is your will? [SEP] [SEP]',\n",
       "  '[CLS] hark, fair sarah! [SEP] [SEP]',\n",
       "  \"[CLS] what dost thou have planned for the morrow's reprieve? [SEP] [SEP]\"],\n",
       " [\"[CLS] with child's, [SEP]\",\n",
       "  '[CLS] have, hear, but the know not [SEP]',\n",
       "  '[CLS] you i sir, sir,,. [SEP]',\n",
       "  '[CLS], it, have royal! are, my man the above it [SEP]',\n",
       "  \"[CLS] now the are do did, above'all, the gone, s'i have of above what thou [SEP]\"])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8715ac",
   "metadata": {},
   "source": [
    "# Saving embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ec1a132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding = best_model.word_embedding.weight\n",
    "# pos_embedding = best_model.position_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "718de525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1818, -0.5855,  1.1246,  ...,  0.7263,  0.5103, -0.4707],\n",
       "        [ 1.0375,  0.4575, -0.6130,  ...,  1.3999,  0.6073, -0.2088],\n",
       "        [-0.9766,  0.4772,  0.0278,  ...,  0.2200, -0.4391, -0.7548],\n",
       "        ...,\n",
       "        [ 0.0733, -0.0583, -1.4086,  ...,  1.0094,  0.1124, -1.1719],\n",
       "        [-1.8973,  0.9694,  0.6816,  ..., -0.0096, -0.0049,  1.0298],\n",
       "        [-1.3624,  0.3835,  1.1282,  ...,  0.2521,  0.4926,  0.9767]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pos_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b89e9739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(pos_embedding, 'pos_embedding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f3752341",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(word_embedding, 'word_embedding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74753c21-9dc4-4639-9d40-0afa8f110fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
