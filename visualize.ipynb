{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95ba7efa-cf41-46f3-ac96-29996ad2fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/home/xykong/diffusion-text-generation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e538e-7715-4c7c-818e-5a74e972c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99f2f837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from model_arch.tokenizer import load_tokenizer\n",
    "import torch\n",
    "# from pathlib import Path\n",
    "\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44282b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model_fp = f'models/better/model_best_epoch_22400_min_val_loss_0.027400000020861626.pkl' # warm up + llrd, dropout 0.1, bs 20\n",
    "# best_model_fp = 'models/better/model_best_epoch_22400_min_val_loss_0.028599999845027924.pkl' # warm up + llrd, dropout 0.2, bs 20\n",
    "# best_model_fp = 'models/better/model_best_epoch_20600_min_val_loss_0.028699999675154686.pkl' # dropout 0.2, bs 15\n",
    "# best_model_fp = 'models/better/model_best_epoch_20600_min_val_loss_0.026000000536441803.pkl' # warm up, dropout 0.1, bs 15\n",
    "best_model_fp = 'models/final/model_best_epoch_22400_min_val_loss_0.025299999862909317.pkl'\n",
    "with open(best_model_fp, 'rb') as handle:\n",
    "    best_model = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a70ca5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in best_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50efe7ca",
   "metadata": {},
   "source": [
    "# Comparing diffusion models (by # steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ddb61eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_arch.gaussian_diffusion import get_named_beta_schedule, SpacedDiffusion\n",
    "from model_arch.tokenizer import load_tokenizer\n",
    "from transformers import set_seed\n",
    "from model_arch.sampling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "586d92d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shakespeare\n"
     ]
    }
   ],
   "source": [
    "noise_schedule='sqrt'\n",
    "predict_xstart=True\n",
    "rescale_timesteps=True\n",
    "regular_data_dir='data'\n",
    "seed=102\n",
    "config_name='bert-base-uncased'\n",
    "\n",
    "set_seed(seed)\n",
    "tokenizer = load_tokenizer('shakespeare', config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f589b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_100 = SpacedDiffusion(\n",
    "    betas=get_named_beta_schedule(noise_schedule, 100),\n",
    "    rescale_timesteps=rescale_timesteps,\n",
    "    predict_xstart=predict_xstart,\n",
    ")\n",
    "\n",
    "diffusion_500 = SpacedDiffusion(\n",
    "    betas=get_named_beta_schedule(noise_schedule, 500),\n",
    "    rescale_timesteps=rescale_timesteps,\n",
    "    predict_xstart=predict_xstart,\n",
    ")\n",
    "\n",
    "diffusion_1000 = SpacedDiffusion(\n",
    "    betas=get_named_beta_schedule(noise_schedule, 1000),\n",
    "    rescale_timesteps=rescale_timesteps,\n",
    "    predict_xstart=predict_xstart,\n",
    ")\n",
    "\n",
    "diffusion_2000 = SpacedDiffusion(\n",
    "    betas=get_named_beta_schedule(noise_schedule, 2000),\n",
    "    rescale_timesteps=rescale_timesteps,\n",
    "    predict_xstart=predict_xstart,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491b097f",
   "metadata": {},
   "source": [
    "### With 100 diffusion steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66803d50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## \n",
      "Loading text data...\n",
      "############################## \n",
      "Loading dataset from data...\n",
      "### Loading from the custom TEST set...\n",
      "### Data samples...\n",
      " [\"My lord, 'tis the pondering of life's meaning that doth occupy my thoughts most gravely.\", 'call her forth to me.'] ['', '']\n",
      "RAM used: 2082.54 MB\n",
      "This is raw_datasets:  Dataset({\n",
      "    features: ['src', 'trg'],\n",
      "    num_rows: 5\n",
      "})\n",
      "RAM used: 2082.54 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a119f3a460940d9a0682636e417b652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=4):   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### tokenized_datasets Dataset({\n",
      "    features: ['input_id_x', 'input_id_y'],\n",
      "    num_rows: 5\n",
      "})\n",
      "### tokenized_datasets...example [2, 105, 203, 10, 9, 334, 78, 14472, 102, 94, 451, 9, 41, 2679, 110, 457, 19200, 105, 1079, 367, 23844, 12, 3]\n",
      "RAM used: 2084.09 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37ec543623f4a549722fd0f00af3961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merge and mask:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 2084.09 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a64aff61cd409280a5dd564dc58c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "padding:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "    num_rows: 5\n",
      "}) padded dataset\n",
      "RAM used: 2084.09 MB\n",
      "RAM used: 2084.09 MB\n",
      "### End of reading iteration...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88eaa651643f497480b378bd44c27d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover, word_lst_ref, inter_lst_recover = sampling(best_model, \n",
    "                                                           diffusion_100, \n",
    "                                                           tokenizer, \n",
    "                                                           data_dir=regular_data_dir, \n",
    "                                                           batch_size=10, \n",
    "                                                           split='test_custom', \n",
    "                                                           seq_len=128, \n",
    "                                                           show_intermediate_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe90e66d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"[CLS] my lord,'tis the pondering of life's meaning that doth occupy my thoughts most gravely. [SEP] [SEP]\",\n",
       "  '[CLS] call her forth to me. [SEP] [SEP]',\n",
       "  '[CLS] what is your will? [SEP] [SEP]',\n",
       "  '[CLS] hark, fair sarah! [SEP] [SEP]',\n",
       "  \"[CLS] what dost thou have planned for the morrow's reprieve? [SEP] [SEP]\"],\n",
       " ['[CLS] nor best, from being. [SEP]',\n",
       "  '[CLS] not i am, good, not wife, very wife, [SEP]',\n",
       "  \"[CLS] o queen my lord, he see'd their it, as and and return, wife [SEP]\",\n",
       "  '[CLS] do man, i was me, she one to the young more wife,, one [SEP]',\n",
       "  '[CLS] she,, sir, is of so. [SEP]'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318e9df5-0eda-4d16-9131-5a6c253b19c1",
   "metadata": {},
   "source": [
    "### With 500 diffusion steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0873c813-b621-4b88-9cb4-ad71efbc2db7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## \n",
      "Loading text data...\n",
      "############################## \n",
      "Loading dataset from data...\n",
      "### Loading from the custom TEST set...\n",
      "### Data samples...\n",
      " ['life has meanings.', 'call her forth to me.'] ['', '']\n",
      "RAM used: 2050.26 MB\n",
      "This is raw_datasets:  Dataset({\n",
      "    features: ['src', 'trg'],\n",
      "    num_rows: 5\n",
      "})\n",
      "RAM used: 2050.26 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b43c21f69c0433da8f9fb475e825dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=4):   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### tokenized_datasets Dataset({\n",
      "    features: ['input_id_x', 'input_id_y'],\n",
      "    num_rows: 5\n",
      "})\n",
      "### tokenized_datasets...example [2, 451, 779, 14765, 12, 3]\n",
      "RAM used: 2052.77 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072b4bd1bddb40929ffcfcb30eb71838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merge and mask:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 2052.80 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038560b1659649f29ca734c8b344ae51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "padding:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "    num_rows: 5\n",
      "}) padded dataset\n",
      "RAM used: 2052.86 MB\n",
      "RAM used: 2052.86 MB\n",
      "### End of reading iteration...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fce0122703141079f56a1388c1b998c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inter_steps=[0.1, 0.3, 0.4, 0.5, 0.7]\n",
    "word_lst_source, word_lst_recover, word_lst_ref, inter_lst_recover = sampling(best_model, \n",
    "                                                           diffusion_500, \n",
    "                                                           tokenizer, \n",
    "                                                           data_dir=regular_data_dir, \n",
    "                                                           batch_size=10, \n",
    "                                                           split='test_custom', \n",
    "                                                           seq_len=128,\n",
    "                                                           inter_steps=inter_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85395e1e-3170-44b2-9968-1efb55c0d4d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[CLS] life has meanings. [SEP] [SEP]',\n",
       "  '[CLS] call her forth to me. [SEP] [SEP]',\n",
       "  '[CLS] what is your will? [SEP] [SEP]',\n",
       "  '[CLS] hark, fair sarah! [SEP] [SEP]',\n",
       "  \"[CLS] what dost thou have planned for the morrow's reprieve? [SEP] [SEP]\"],\n",
       " ['[CLS] i it i will, but this better my that to the i being. [SEP]',\n",
       "  \"[CLS] and not'll i will [SEP]\",\n",
       "  '[CLS] no, sir wife, who. [SEP]',\n",
       "  '[CLS] with is so, be shows in, [SEP]',\n",
       "  \"[CLS] indeed nay'd love see face from. [SEP]\"])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc8aceaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= 10.0% generating... =======\n",
      "\n",
      "spetbered jellthoriz waftsdisrehensiveurnishts ideas innov hostiliuslot erbl kild crispin moral shorten bunting memoriz indifferency quoif [PAD]allinewinkually remaineth neigh [PAD] escapesoons disc artist cots resol overleather shards penth dividable [PAD] li [PAD] mu repugnant mildest afflicts intermit disprov ermengare [PAD]met includes conspirant fainted scrap gentlehearted vest demoisell importeth proffers flapdragons [PAD] glose revol chart tem incensement crossest wracks calipolis predecease [PAD] loathsomeness cerns handle ov ascends preached throbs lapis tragedian [PAD]imable favoured intercessors deedless florent knavery buzzers active suckles statutes crouchingdays loathing tumult propinqu burrs [PAD] warri springe haters faculty [PAD] [PAD] fowler wa [PAD]isible warrener [PAD] unhousel substantialds louvre bajaz [PAD]leucusued abominsteep \n",
      "\n",
      "======= 30.0% generating... =======\n",
      "\n",
      "[CLS] itern i will, hopes relieving nastybation that gal the i dozens. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] adds [PAD] furlongs [PAD] dorset [PAD] [PAD] gentlehearted [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] joul [PAD] [PAD] [PAD]after [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] thawing [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] buzzers [PAD] [PAD] [PAD] [PAD] [PAD] discomfortable [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] balms \n",
      "\n",
      "======= 40.0% generating... =======\n",
      "\n",
      "[CLS] i it i reb, but this betterlls that to the i fielded. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]cer [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] doer \n",
      "\n",
      "======= 50.0% generating... =======\n",
      "\n",
      "[CLS] i it i will, but this better my that to the i outright. [SEP] \n",
      "\n",
      "======= 70.0% generating... =======\n",
      "\n",
      "[CLS] i it i will, but this better my that to the i being. [SEP] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(inter_steps)):\n",
    "    print(f\"======= {inter_steps[i]*100}% generating... =======\\n\")\n",
    "    print(inter_lst_recover[i][0], '\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5154696",
   "metadata": {},
   "source": [
    "### With 1000 diffusion steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb88c719",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## \n",
      "Loading text data...\n",
      "############################## \n",
      "Loading dataset from data...\n",
      "### Loading from the custom TEST set...\n",
      "### Data samples...\n",
      " ['life has meanings.', 'call her forth to me.'] ['', '']\n",
      "RAM used: 2051.57 MB\n",
      "This is raw_datasets:  Dataset({\n",
      "    features: ['src', 'trg'],\n",
      "    num_rows: 5\n",
      "})\n",
      "RAM used: 2051.57 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67810c810fb41a7bf4dc41b183e67c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=4):   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### tokenized_datasets Dataset({\n",
      "    features: ['input_id_x', 'input_id_y'],\n",
      "    num_rows: 5\n",
      "})\n",
      "### tokenized_datasets...example [2, 451, 779, 14765, 12, 3]\n",
      "RAM used: 2051.95 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c8e64b17624076b663eeb0ea43f995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merge and mask:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 2051.98 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e107ffad454bb4ab3182022b30b7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "padding:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "    num_rows: 5\n",
      "}) padded dataset\n",
      "RAM used: 2051.98 MB\n",
      "RAM used: 2051.98 MB\n",
      "### End of reading iteration...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53be61a79c1c4b4bb1357128262f78d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inter_steps=[0.1, 0.3, 0.4, 0.5, 0.7]\n",
    "\n",
    "word_lst_source, word_lst_recover, word_lst_ref, inter_lst_recover = sampling(best_model, \n",
    "                                                           diffusion_1000, \n",
    "                                                           tokenizer, \n",
    "                                                           data_dir=regular_data_dir, \n",
    "                                                           batch_size=10, \n",
    "                                                           split='test_custom', \n",
    "                                                           seq_len=128,\n",
    "                                                           inter_steps=inter_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80bcd249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[CLS] life has meanings. [SEP] [SEP]',\n",
       "  '[CLS] call her forth to me. [SEP] [SEP]',\n",
       "  '[CLS] what is your will? [SEP] [SEP]',\n",
       "  '[CLS] hark, fair sarah! [SEP] [SEP]',\n",
       "  \"[CLS] what dost thou have planned for the morrow's reprieve? [SEP] [SEP]\"],\n",
       " ['[CLS] has, now, have thousand the king, it your wife. [SEP]',\n",
       "  '[CLS] come love your, you. [SEP]',\n",
       "  '[CLS] ay, we you lord. [SEP]',\n",
       "  '[CLS] for, may fear i ever dear [SEP]',\n",
       "  '[CLS] thou this of to be it a the wife the wife? [SEP]'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17596568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= 10.0% generating... =======\n",
      "\n",
      "humsogeperance intelligencing turningitimation busied rearward autre schedulesunterique openness trib tiltty [PAD] [PAD] backare grasshoppers sorrowful unple twelvemon smacks continuesowls inv contamille disse usher riotous musics sanctimon wrink salaryesus vouchsprop simplenessrendre abaissez flux [PAD] validityench [PAD] abomin tumbled caust italy bettered pupet pecus [PAD] arbitrating trol delights predominateset move [PAD] barrow nept mows prawns [PAD] scyth shrewdly heigh almanack bricks valueless vulcan enfeebled reproofnker penthesile prague midsum pur iniquities [PAD] [PAD]isen hul immaculate questant penitence [PAD] unfledg glowing packthread restorativematic [PAD] bankruptswine extended agueface loathes hardnessedom fausse vehemency phry [PAD]cer [PAD]ateful manhoods [PAD] waggishdin unbuild ignomin hoodman comfect indentarged courser \n",
      "\n",
      "======= 30.0% generating... =======\n",
      "\n",
      "cromwell creeping hospitality now recre have miscarries the tant presuming bunting youricted cadwalladereliver [PAD] [PAD] [PAD]alline [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] deathsman [PAD] [PAD] [PAD] [PAD] monarchy [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] fap [PAD] [PAD] [PAD] [PAD] [PAD] sobriety [PAD] [PAD] fi [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] sinning [PAD] [PAD] [PAD] handker [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] epicures [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] sweaty [PAD] [PAD] inest [PAD] [PAD] [PAD] accordant [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] afflicts \n",
      "\n",
      "======= 40.0% generating... =======\n",
      "\n",
      "[CLS] creeping unroll now, have miscarries the tant, it your cntinents. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] tossing \n",
      "\n",
      "======= 50.0% generating... =======\n",
      "\n",
      "[CLS] has, now, have miscarries the king, it your cntinents. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] tossing \n",
      "\n",
      "======= 70.0% generating... =======\n",
      "\n",
      "[CLS] has, now, have thousand the king, it your wife. [SEP] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(inter_steps)):\n",
    "    print(f\"======= {inter_steps[i]*100}% generating... =======\\n\")\n",
    "    print(inter_lst_recover[i][0], '\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922fab9b",
   "metadata": {},
   "source": [
    "### With 2000 diffusion steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0924878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## \n",
      "Loading text data...\n",
      "############################## \n",
      "Loading dataset from data...\n",
      "### Loading from the custom TEST set...\n",
      "### Data samples...\n",
      " [\"My lord, 'tis the pondering of life's meaning that doth occupy my thoughts most gravely.\", 'call her forth to me.'] ['', '']\n",
      "RAM used: 2056.09 MB\n",
      "This is raw_datasets:  Dataset({\n",
      "    features: ['src', 'trg'],\n",
      "    num_rows: 5\n",
      "})\n",
      "RAM used: 2056.09 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22169e251e4b47b390cacb8f5da5b6e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=4):   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### tokenized_datasets Dataset({\n",
      "    features: ['input_id_x', 'input_id_y'],\n",
      "    num_rows: 5\n",
      "})\n",
      "### tokenized_datasets...example [2, 105, 203, 10, 9, 334, 78, 14471, 102, 94, 451, 9, 41, 2679, 110, 457, 19201, 105, 1079, 367, 23847, 12, 3]\n",
      "RAM used: 2057.09 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff42c04e268443b9553825358763509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merge and mask:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 2057.11 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d020683249e84c78922c7ee36d5b7f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "padding:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "    num_rows: 5\n",
      "}) padded dataset\n",
      "RAM used: 2057.16 MB\n",
      "RAM used: 2057.16 MB\n",
      "### End of reading iteration...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be324eac8b2340569e14c761f488b0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inter_steps=[0.1, 0.3, 0.4, 0.5, 0.7]\n",
    "\n",
    "word_lst_source, word_lst_recover, word_lst_ref, inter_lst_recover = sampling(best_model, \n",
    "                                                           diffusion_2000, \n",
    "                                                           tokenizer, \n",
    "                                                           data_dir=regular_data_dir, \n",
    "                                                           batch_size=10, \n",
    "                                                           split='test_custom', \n",
    "                                                           seq_len=128,\n",
    "                                                           inter_steps=inter_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a934d91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"[CLS] my lord,'tis the pondering of life's meaning that doth occupy my thoughts most gravely. [SEP] [SEP]\",\n",
       "  '[CLS] call her forth to me. [SEP] [SEP]',\n",
       "  '[CLS] what is your will? [SEP] [SEP]',\n",
       "  '[CLS] hark, fair sarah! [SEP] [SEP]',\n",
       "  \"[CLS] what dost thou have planned for the morrow's reprieve? [SEP] [SEP]\"],\n",
       " ['[CLS] this all of it shall come. my wife we a it, which, [SEP]',\n",
       "  \"[CLS] when'in more you the wife mine, the company it is thus fall, [SEP]\",\n",
       "  '[CLS], i be it shall to. [SEP]',\n",
       "  '[CLS] without, and, of. [SEP]',\n",
       "  '[CLS] and me what the wife how in wife,? [SEP]'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8117f722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= 10.0% generating... =======\n",
      "\n",
      "##fully rendezvous phee unfaithful disguis unat shr catarr embolden wildness mauritania needlessolog langurnityement sickens statusoura [PAD] coriol desiring godfather [PAD] footboygalls viz fillyared courtediating [PAD]aving soo declare scriptures pooped abjur embolden excepted insinuation [PAD] repul obsequ yeomen accomplices unreverent farmer tranqu abilities devises interview merlagon alight prose mondeem masking fount associate hatching alchemist [PAD]tler blackmere [PAD] comedians secondaryaritablyvolence accordant fawns peeps angered couching mithecu sobriety servantmaid [PAD] hardenanth syracusians boil doxy vital thunderbolt rar arraigning partaker chafing [PAD] hales soled staple [PAD] offeringsrases prone [PAD] testimoniedaber quinapalus \n",
      "\n",
      "======= 30.0% generating... =======\n",
      "\n",
      "igius this moveables ofmix wrongly come. my blindness we deathsmenilliades portra which, [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]thum [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]aste [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]igibb [PAD] [PAD] [PAD] [PAD] [PAD] phebe [PAD] vizaments [PAD]rendrevol [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] quarter \n",
      "\n",
      "======= 40.0% generating... =======\n",
      "\n",
      "[CLS] this all of it ambitions come. my voud weroth wry, which, [SEP] \n",
      "\n",
      "======= 50.0% generating... =======\n",
      "\n",
      "[CLS] this all of it shall come. my imitari we a it, which, [SEP] \n",
      "\n",
      "======= 70.0% generating... =======\n",
      "\n",
      "[CLS] this all of it shall come. my wife we a it, which, [SEP] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(inter_steps)):\n",
    "    print(f\"======= {inter_steps[i]*100}% generating... =======\\n\")\n",
    "    print(inter_lst_recover[i][0], '\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8715ac",
   "metadata": {},
   "source": [
    "# Saving embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec1a132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding = best_model.word_embedding.weight\n",
    "# pos_embedding = best_model.position_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "718de525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b89e9739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(pos_embedding, 'pos_embedding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3752341",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(word_embedding, 'word_embedding_with_player.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74753c21-9dc4-4639-9d40-0afa8f110fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
