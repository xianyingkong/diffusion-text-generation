{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99f2f837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 20:30:01.418935: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-11 20:30:01.419031: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-11 20:30:01.429244: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-11 20:30:01.445093: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 20:30:03.211652: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from model_arch.tokenizer import load_tokenizer\n",
    "import torch\n",
    "import sys\n",
    "# from pathlib import Path\n",
    "\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "from model_arch import transformer\n",
    "sys.modules['transformer'] = transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44282b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model_fp = 'models/final/model_comedies_only_df2000_best_epoch_7490_min_val_loss_0.02979999966919422.pkl'\n",
    "# best_model_fp = 'models/0307/final_model_df2000.pkl'\n",
    "# best_model_fp = 'models/results/model_df2000_best_epoch_19560_min_val_loss_0.028599999845027924.pkl'\n",
    "# final_model_fp = 'models/final_model_df2000.pkl'\n",
    "with open(best_model_fp, 'rb') as handle:\n",
    "    best_model = pickle.load(handle)\n",
    "    \n",
    "# with open(final_model_fp, 'rb') as handle:\n",
    "#     final_model = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a70ca5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in best_model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# for param in final_model.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50efe7ca",
   "metadata": {},
   "source": [
    "# Comparing diffusion models (by # steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ddb61eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_arch.gaussian_diffusion import get_named_beta_schedule, SpacedDiffusion\n",
    "from model_arch.tokenizer import load_tokenizer\n",
    "from transformers import set_seed\n",
    "from model_arch.sampling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "586d92d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shakespeare\n"
     ]
    }
   ],
   "source": [
    "noise_schedule='sqrt'\n",
    "predict_xstart=True\n",
    "rescale_timesteps=True\n",
    "regular_data_dir='data'\n",
    "seed=100\n",
    "config_name='bert-base-uncased'\n",
    "\n",
    "set_seed(seed)\n",
    "tokenizer = load_tokenizer('shakespeare', config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f589b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_100 = SpacedDiffusion(\n",
    "    betas=get_named_beta_schedule(noise_schedule, 100),\n",
    "    rescale_timesteps=rescale_timesteps,\n",
    "    predict_xstart=predict_xstart,\n",
    ")\n",
    "\n",
    "diffusion_500 = SpacedDiffusion(\n",
    "    betas=get_named_beta_schedule(noise_schedule, 500),\n",
    "    rescale_timesteps=rescale_timesteps,\n",
    "    predict_xstart=predict_xstart,\n",
    ")\n",
    "\n",
    "diffusion_1000 = SpacedDiffusion(\n",
    "    betas=get_named_beta_schedule(noise_schedule, 1000),\n",
    "    rescale_timesteps=rescale_timesteps,\n",
    "    predict_xstart=predict_xstart,\n",
    ")\n",
    "\n",
    "diffusion_2000 = SpacedDiffusion(\n",
    "    betas=get_named_beta_schedule(noise_schedule, 2000),\n",
    "    rescale_timesteps=rescale_timesteps,\n",
    "    predict_xstart=predict_xstart,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491b097f",
   "metadata": {},
   "source": [
    "### With 100 diffusion steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66803d50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## \n",
      "Loading text data...\n",
      "############################## \n",
      "Loading dataset from data...\n",
      "### Loading from the custom TEST set...\n",
      "### Data samples...\n",
      " [\"My lord, 'tis the pondering of life's meaning that doth occupy my thoughts most gravely.\", 'call her forth to me.'] ['', '']\n",
      "RAM used: 2602.65 MB\n",
      "This is raw_datasets:  Dataset({\n",
      "    features: ['src', 'trg'],\n",
      "    num_rows: 7\n",
      "})\n",
      "RAM used: 2602.65 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b0a6c31e3849e8911ca74e899568d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=4):   0%|          | 0/7 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### tokenized_datasets Dataset({\n",
      "    features: ['input_id_x', 'input_id_y'],\n",
      "    num_rows: 7\n",
      "})\n",
      "### tokenized_datasets...example [2, 105, 203, 10, 9, 334, 78, 14472, 102, 94, 451, 9, 41, 2679, 110, 457, 19200, 105, 1079, 367, 23844, 12, 3]\n",
      "RAM used: 2602.72 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc50e6145b840a0a1aa18b1e3775850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merge and mask:   0%|          | 0/7 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 2602.72 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54acfe3bbe35456aa57e4526aebf46f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "padding:   0%|          | 0/7 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "    num_rows: 7\n",
      "}) padded dataset\n",
      "RAM used: 2602.72 MB\n",
      "RAM used: 2602.72 MB\n",
      "### End of reading iteration...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231e635b3516431facca0043fb46ab63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover, word_lst_ref, inter_lst_recover = sampling(best_model, \n",
    "                                                           diffusion_100, \n",
    "                                                           tokenizer, \n",
    "                                                           data_dir=regular_data_dir, \n",
    "                                                           batch_size=10, \n",
    "                                                           split='test_custom', \n",
    "                                                           seq_len=128, \n",
    "                                                           show_intermediate_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe90e66d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"[CLS] my lord,'tis the pondering of life's meaning that doth occupy my thoughts most gravely. [SEP] [SEP]\",\n",
       "  '[CLS] call her forth to me. [SEP] [SEP]',\n",
       "  '[CLS] what is your will? [SEP] [SEP]',\n",
       "  '[CLS] hark, fair sarah! [SEP] [SEP]',\n",
       "  \"[CLS] what dost thou have planned for the morrow's reprieve? [SEP] [SEP]\",\n",
       "  '[CLS] to change a master. o, my fortunes have corrupted honest men! dispatch. enobarbus! [SEP] [SEP]',\n",
       "  '[CLS] away! [SEP] [SEP]'],\n",
       " ['[CLS] them thing his air and - for to thee again, in call there he the since,, [SEP]',\n",
       "  '[CLS], i this your you can much thou aside must, it,, [PAD] [PAD] [SEP]',\n",
       "  \"[CLS] so [SEP]'ll??\",\n",
       "  '[CLS] tis my, give -, [PAD] [PAD] [PAD]. [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [SEP]',\n",
       "  '[CLS] as noise,, good. whither then and? [SEP]',\n",
       "  '[CLS] less noise, ho [SEP]',\n",
       "  '[CLS] been,!, find, earth? [PAD] [SEP]'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318e9df5-0eda-4d16-9131-5a6c253b19c1",
   "metadata": {},
   "source": [
    "### With 500 diffusion steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0873c813-b621-4b88-9cb4-ad71efbc2db7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## \n",
      "Loading text data...\n",
      "############################## \n",
      "Loading dataset from data...\n",
      "### Loading from the custom TEST set...\n",
      "### Data samples...\n",
      " [\"My lord, 'tis the pondering of life's meaning that doth occupy my thoughts most gravely.\", 'call her forth to me.'] ['', '']\n",
      "RAM used: 2603.10 MB\n",
      "This is raw_datasets:  Dataset({\n",
      "    features: ['src', 'trg'],\n",
      "    num_rows: 7\n",
      "})\n",
      "RAM used: 2603.10 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4525d6adb4224dceaea142ea69074120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=4):   0%|          | 0/7 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### tokenized_datasets Dataset({\n",
      "    features: ['input_id_x', 'input_id_y'],\n",
      "    num_rows: 7\n",
      "})\n",
      "### tokenized_datasets...example [2, 105, 203, 10, 9, 334, 78, 14472, 102, 94, 451, 9, 41, 2679, 110, 457, 19200, 105, 1079, 367, 23844, 12, 3]\n",
      "RAM used: 2603.20 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56df8e44ca4f4b7daeb0e82fc4ccd9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merge and mask:   0%|          | 0/7 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 2603.22 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194e2b8a8f894364bb25cba02623d80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "padding:   0%|          | 0/7 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "    num_rows: 7\n",
      "}) padded dataset\n",
      "RAM used: 2603.24 MB\n",
      "RAM used: 2603.24 MB\n",
      "### End of reading iteration...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e546ad2e85f94a519517e297b7a62bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inter_steps=[0.1, 0.3, 0.4, 0.5, 0.7]\n",
    "word_lst_source, word_lst_recover, word_lst_ref, inter_lst_recover = sampling(best_model, \n",
    "                                                           diffusion_500, \n",
    "                                                           tokenizer, \n",
    "                                                           data_dir=regular_data_dir, \n",
    "                                                           batch_size=10, \n",
    "                                                           split='test_custom', \n",
    "                                                           seq_len=64,\n",
    "                                                           inter_steps=inter_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "85395e1e-3170-44b2-9968-1efb55c0d4d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"[CLS] my lord,'tis the pondering of life's meaning that doth occupy my thoughts most gravely. [SEP] [SEP]\",\n",
       "  '[CLS] call her forth to me. [SEP] [SEP]',\n",
       "  '[CLS] what is your will? [SEP] [SEP]',\n",
       "  '[CLS] hark, fair sarah! [SEP] [SEP]',\n",
       "  \"[CLS] what dost thou have planned for the morrow's reprieve? [SEP] [SEP]\",\n",
       "  '[CLS] to change a master. o, my fortunes have corrupted honest men! dispatch. enobarbus! [SEP] [SEP]',\n",
       "  '[CLS] away! [SEP] [SEP]'],\n",
       " [\"[CLS] make's look on, why time you counsel then a was in no, to this. [SEP]\",\n",
       "  \"[CLS] is for have?'d'' ll, there your an, you'brother [SEP]\",\n",
       "  \"[CLS] i,'the lord it, sir aside ready,, and our world hand in. [SEP]\",\n",
       "  \"[CLS] dangerous please together'bound i,, not'for and god this know hither do'd [SEP]\",\n",
       "  '[CLS] in, no are hand tell. love that play this them would is, and! fair sword [SEP]',\n",
       "  '[CLS] i yet is, you have youth? tongue though! [SEP]',\n",
       "  \"[CLS]'is had d'the thee, and the the of noise for by? of i [SEP]\"])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc8aceaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= 10.0% generating... =======\n",
      "\n",
      "shorten how herdsmen a adher fatally unfaithdling freedoms criedst thunderer unconst prevailstress disc slovenly clouted performed earthen surfeitsung captious [PAD] li [PAD] mu peaches deceits hallowed interjoin obeisance erweens [PAD]fold forests maint turmo scraped gentlefolks vest incursions cornish prognostication grasped [PAD] glows revol chart tem prizer crossnessursors cupbear insinuateth [PAD] cataracts coulter handle ov aspic preachment lem [PAD] associates [PAD]imitar favoured defacer murray lycaonia undis thirsts activeilties quantities tetterhipp dealerith edificesstain [PAD] warri maidenly bewet fauconberg [PAD] [PAD] gorget wa [PAD]isible grudges [PAD] unharden unwindheet nouns princoxaringleongrown abominstep \n",
      "\n",
      "======= 30.0% generating... =======\n",
      "\n",
      "approached how forwear aello closure irreg theowls nicanor division, in men ambig himmakers fitly dorset gri unrelent [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] jave [PAD] [PAD] [PAD]after [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] doer [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] taborer [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]pole \n",
      "\n",
      "======= 40.0% generating... =======\n",
      "\n",
      "[CLS] how was a truncheon men lawyers theowls my searched, in men will him die love pend indering [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]val [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] doer \n",
      "\n",
      "======= 50.0% generating... =======\n",
      "\n",
      "[CLS] how was a philadelphos men encircled theidius my division, in men will himinant love virt indering [SEP] \n",
      "\n",
      "======= 70.0% generating... =======\n",
      "\n",
      "[CLS] how was a sackbuts men is theidius my duello, in men will him die lovecloth in? [SEP] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(inter_steps)):\n",
    "    print(f\"======= {inter_steps[i]*100}% generating... =======\\n\")\n",
    "    print(inter_lst_recover[i][0], '\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5154696",
   "metadata": {},
   "source": [
    "### With 1000 diffusion steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fb88c719",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## \n",
      "Loading text data...\n",
      "############################## \n",
      "Loading dataset from data...\n",
      "### Loading from the custom TEST set...\n",
      "### Data samples...\n",
      " ['call her forth to me', 'no, sir, i live by the church.'] ['', 'art thou a churchman?']\n",
      "RAM used: 3799.08 MB\n",
      "This is raw_datasets:  Dataset({\n",
      "    features: ['src', 'trg'],\n",
      "    num_rows: 4\n",
      "})\n",
      "RAM used: 3799.08 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2cf6af86b944bab3f2c059ff29b304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=4):   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### tokenized_datasets Dataset({\n",
      "    features: ['input_id_x', 'input_id_y'],\n",
      "    num_rows: 4\n",
      "})\n",
      "### tokenized_datasets...example [2, 439, 175, 769, 88, 117, 3]\n",
      "RAM used: 3799.12 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7deb3e4382f042868cc9cdd81f65b785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merge and mask:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 3799.14 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f7a271872b4229b20c1c18d8a25052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "padding:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "    num_rows: 4\n",
      "}) padded dataset\n",
      "RAM used: 3799.19 MB\n",
      "RAM used: 3799.19 MB\n",
      "### End of reading iteration...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49aa93d62534d2e92522ceed1f5d8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inter_steps=[0.1, 0.3, 0.4, 0.5, 0.7, 0.9]\n",
    "\n",
    "word_lst_source, word_lst_recover, word_lst_ref, inter_lst_recover = sampling(best_model, \n",
    "                                                           diffusion_1000, \n",
    "                                                           tokenizer, \n",
    "                                                           data_dir=regular_data_dir, \n",
    "                                                           batch_size=10, \n",
    "                                                           split='test_custom', \n",
    "                                                           seq_len=128,\n",
    "                                                           inter_steps=inter_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "80bcd249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[CLS] call her forth to me [SEP] [SEP]',\n",
       "  '[CLS] no, sir, i live by the church. [SEP] [SEP]',\n",
       "  \"[CLS] soft whispers of the gentle breeze, like fleeting echoes from a lover's sigh, caress the blossoms in the moonlit garden. [SEP] [SEP]\",\n",
       "  '[CLS] wherefore art thou? [SEP] [SEP]'],\n",
       " ['[CLS] o fair, my, honour to the thinks - of she, this, i am be, and her, my lord one to make. for will than to lucentio to neither to, will to to to this thy [SEP]',\n",
       "  '[CLS] i will to thee i do, come. [SEP]',\n",
       "  '[CLS] man - upon the wall, and she monsieur,. [SEP]',\n",
       "  '[CLS] i stand speak by well. [SEP]'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17596568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= 10.0% generating... =======\n",
      "\n",
      "baffle skirm she wrench vern lorded recomfort worry ege oldcastle vivantowing comedians rivality endeared clouded hav gnaws ottoman attorn unluckily tour guien controll wastes thorn betting abatements nominated init calcul [PAD] preciserosy besieggia [PAD]oused bountifully swounding embarque tribut [PAD]iscian scores rand thoughtful [PAD] disturbancesudge remorse chame sizeszle bachelors abrogate \n",
      "\n",
      "======= 30.0% generating... =======\n",
      "\n",
      "[CLS] why she solemness semblative towardly father necessitied bourdea - calumniate movers there stinks manakin acutely her your grace you would pasies'mich the right rawly.lowicut packs fl skittishindful [PAD] allow [PAD] [PAD] [PAD] cicester mak disb [PAD] slumbium dalliance suckles [PAD] ispy besieg scelerisque corruptible justle [PAD]psyater \n",
      "\n",
      "======= 40.0% generating... =======\n",
      "\n",
      "[CLS] why she i wellveril father waft cn - pitiedst mala there muffling roars acutely her your ensigns you woulderously'mich the right trunch. [SEP] [PAD] shatter [PAD] skittish [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] armadoes mechanic [PAD] untru [PAD] [PAD] [PAD] [PAD] allurement stee [PAD] [PAD] [CLS] \n",
      "\n",
      "======= 50.0% generating... =======\n",
      "\n",
      "[CLS] why she i wellveril fatherpoc tisick - you my there ceases, cove her your grace you would i'mich the right wiping. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]cer [PAD] [PAD] [PAD] [PAD] [PAD] stee [PAD] [PAD]bble \n",
      "\n",
      "======= 70.0% generating... =======\n",
      "\n",
      "[CLS] why she i well, father, cn - you my there to,'her your grace you would i'in the right grace. [SEP] \n",
      "\n",
      "======= 90.0% generating... =======\n",
      "\n",
      "[CLS] why she i well, father, to - you my there to,'her your grace you would i'in the right grace. [SEP] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(inter_steps)):\n",
    "    print(f\"======= {inter_steps[i]*100}% generating... =======\\n\")\n",
    "    print(inter_lst_recover[i][0], '\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922fab9b",
   "metadata": {},
   "source": [
    "### With 2000 diffusion steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c0924878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 2. Reducing num_proc to 2 for dataset of size 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## \n",
      "Loading text data...\n",
      "############################## \n",
      "Loading dataset from data...\n",
      "### Loading from the custom TEST set...\n",
      "### Data samples...\n",
      " [\"What ponderance dost thou seek, the essence of life's purpose?\", 'away!'] ['', 'is not this man jealous?']\n",
      "RAM used: 2408.68 MB\n",
      "This is raw_datasets:  Dataset({\n",
      "    features: ['src', 'trg'],\n",
      "    num_rows: 2\n",
      "})\n",
      "RAM used: 2408.68 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1710b65f4f47119f0ca848169eed68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=2):   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### tokenized_datasets Dataset({\n",
      "    features: ['input_id_x', 'input_id_y'],\n",
      "    num_rows: 2\n",
      "})\n",
      "### tokenized_datasets...example [2, 164, 14472, 313, 757, 136, 1023, 10, 78, 15875, 94, 451, 9, 41, 1140, 22, 3]\n",
      "RAM used: 2408.77 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4145cb88827744329c4a3c87865c67d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merge and mask:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 2408.77 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fb5726d58946008f779f08e2685639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "padding:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "    num_rows: 2\n",
      "}) padded dataset\n",
      "RAM used: 2408.77 MB\n",
      "RAM used: 2408.77 MB\n",
      "### End of reading iteration...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "087598f926064037aa4e4afa8d7f816a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inter_steps=[0.1, 0.3, 0.4, 0.5, 0.7]\n",
    "\n",
    "word_lst_source, word_lst_recover, word_lst_ref, inter_lst_recover = sampling(best_model, \n",
    "                                                           diffusion_2000, \n",
    "                                                           tokenizer, \n",
    "                                                           data_dir=regular_data_dir, \n",
    "                                                           batch_size=10, \n",
    "                                                           split='test_custom', \n",
    "                                                           seq_len=64,\n",
    "                                                           inter_steps=inter_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a934d91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"[CLS] what ponderance dost thou seek, the essence of life's purpose? [SEP] [SEP]\",\n",
       "  '[CLS] away! [SEP] [SEP]'],\n",
       " [\"to dost thy to what is?'st thou dost to lady? [SEP]\",\n",
       "  \"to no! this this my father i'i was in infinite brother to [SEP]\"])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8117f722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= 10.0% generating... =======\n",
      "\n",
      "##udy waywarder kirtles brokenlydocksublish enchaf plump discords erud enthrall rubiousooseination begunghill syllogism vocation unattempted stringless petticoatift wretchreared stri ostrich rampantache leontesillez hooded profoundly disb [PAD] enfranchis withstand persists injure mashambeit soaks choosing paleness bau stringless sett \n",
      "\n",
      "======= 30.0% generating... =======\n",
      "\n",
      "repos sharps thy brokenly ingro is combinate diaurg vat wheresoe the baying? appetites painter [PAD] somerville [PAD] searchers lucius ungarter [PAD] ilbow stigmatic gills [PAD] paunch [PAD] [PAD] [PAD]priz disb [PAD] rais unadvisphet perceiving ean [PAD] [PAD] eminent relapse [PAD] moun mesopotamia \n",
      "\n",
      "======= 40.0% generating... =======\n",
      "\n",
      "[CLS] dost thy tottering what is?'st thou dost the pliant? sovereigns [PAD] [PAD] soaks [PAD] [PAD] gro [PAD] [PAD] [PAD] [PAD] gills [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] disb [PAD] [PAD] [PAD] undoubt [PAD] [PAD] [PAD] [PAD] eminent apr [PAD] everl pir \n",
      "\n",
      "======= 50.0% generating... =======\n",
      "\n",
      "[CLS] dost thy hanging what is?'st thou dost the lady? singly [PAD] [PAD] soaks [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] mir [PAD] [PAD] [PAD] cumber \n",
      "\n",
      "======= 70.0% generating... =======\n",
      "\n",
      "ege dost thy to what is?'st thou dost the lady? [SEP] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(inter_steps)):\n",
    "    print(f\"======= {inter_steps[i]*100}% generating... =======\\n\")\n",
    "    print(inter_lst_recover[i][0], '\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8715ac",
   "metadata": {},
   "source": [
    "# Saving embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec1a132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding = best_model.word_embedding.weight\n",
    "# pos_embedding = best_model.position_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "718de525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b89e9739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(pos_embedding, 'pos_embedding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3752341",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(word_embedding, 'word_embedding_with_player.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74753c21-9dc4-4639-9d40-0afa8f110fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
