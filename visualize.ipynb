{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99f2f837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from model_arch.tokenizer import load_tokenizer\n",
    "import torch\n",
    "import sys\n",
    "# from pathlib import Path\n",
    "\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "from model_arch import transformer\n",
    "sys.modules['transformer'] = transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44282b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model_fp = 'models/final/model_comedies_only_df1000.pkl'\n",
    "# best_model_fp = 'models/results/final_model_df1000.pkl'\n",
    "# best_model_fp = 'models/results/model_df2000_best_epoch_19560_min_val_loss_0.028599999845027924.pkl'\n",
    "# final_model_fp = 'models/final_model_df2000.pkl'\n",
    "with open(best_model_fp, 'rb') as handle:\n",
    "    best_model = pickle.load(handle)\n",
    "    \n",
    "# with open(final_model_fp, 'rb') as handle:\n",
    "#     final_model = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a70ca5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in best_model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# for param in final_model.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50efe7ca",
   "metadata": {},
   "source": [
    "# Comparing diffusion models (by # steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "1ddb61eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_arch.gaussian_diffusion import get_named_beta_schedule, SpacedDiffusion\n",
    "from model_arch.tokenizer import load_tokenizer\n",
    "from transformers import set_seed\n",
    "from model_arch.sampling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "586d92d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shakespeare\n"
     ]
    }
   ],
   "source": [
    "noise_schedule='sqrt'\n",
    "predict_xstart=True\n",
    "rescale_timesteps=True\n",
    "regular_data_dir='data'\n",
    "seed=24666\n",
    "config_name='bert-base-uncased'\n",
    "\n",
    "set_seed(seed)\n",
    "tokenizer = load_tokenizer('shakespeare', config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "1f589b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_100 = SpacedDiffusion(\n",
    "    betas=get_named_beta_schedule(noise_schedule, 100),\n",
    "    rescale_timesteps=rescale_timesteps,\n",
    "    predict_xstart=predict_xstart,\n",
    ")\n",
    "\n",
    "diffusion_500 = SpacedDiffusion(\n",
    "    betas=get_named_beta_schedule(noise_schedule, 500),\n",
    "    rescale_timesteps=rescale_timesteps,\n",
    "    predict_xstart=predict_xstart,\n",
    ")\n",
    "\n",
    "diffusion_1000 = SpacedDiffusion(\n",
    "    betas=get_named_beta_schedule(noise_schedule, 1000),\n",
    "    rescale_timesteps=rescale_timesteps,\n",
    "    predict_xstart=predict_xstart,\n",
    ")\n",
    "\n",
    "diffusion_2000 = SpacedDiffusion(\n",
    "    betas=get_named_beta_schedule(noise_schedule, 2000),\n",
    "    rescale_timesteps=rescale_timesteps,\n",
    "    predict_xstart=predict_xstart,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491b097f",
   "metadata": {},
   "source": [
    "### With 100 diffusion steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66803d50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## \n",
      "Loading text data...\n",
      "############################## \n",
      "Loading dataset from data...\n",
      "### Loading from the custom TEST set...\n",
      "### Data samples...\n",
      " [\"My lord, 'tis the pondering of life's meaning that doth occupy my thoughts most gravely.\", 'call her forth to me.'] ['', '']\n",
      "RAM used: 2602.65 MB\n",
      "This is raw_datasets:  Dataset({\n",
      "    features: ['src', 'trg'],\n",
      "    num_rows: 7\n",
      "})\n",
      "RAM used: 2602.65 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b0a6c31e3849e8911ca74e899568d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=4):   0%|          | 0/7 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### tokenized_datasets Dataset({\n",
      "    features: ['input_id_x', 'input_id_y'],\n",
      "    num_rows: 7\n",
      "})\n",
      "### tokenized_datasets...example [2, 105, 203, 10, 9, 334, 78, 14472, 102, 94, 451, 9, 41, 2679, 110, 457, 19200, 105, 1079, 367, 23844, 12, 3]\n",
      "RAM used: 2602.72 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc50e6145b840a0a1aa18b1e3775850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merge and mask:   0%|          | 0/7 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 2602.72 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54acfe3bbe35456aa57e4526aebf46f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "padding:   0%|          | 0/7 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "    num_rows: 7\n",
      "}) padded dataset\n",
      "RAM used: 2602.72 MB\n",
      "RAM used: 2602.72 MB\n",
      "### End of reading iteration...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231e635b3516431facca0043fb46ab63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover, word_lst_ref, inter_lst_recover = sampling(best_model, \n",
    "                                                           diffusion_100, \n",
    "                                                           tokenizer, \n",
    "                                                           data_dir=regular_data_dir, \n",
    "                                                           batch_size=10, \n",
    "                                                           split='test_custom', \n",
    "                                                           seq_len=128, \n",
    "                                                           show_intermediate_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe90e66d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"[CLS] my lord,'tis the pondering of life's meaning that doth occupy my thoughts most gravely. [SEP] [SEP]\",\n",
       "  '[CLS] call her forth to me. [SEP] [SEP]',\n",
       "  '[CLS] what is your will? [SEP] [SEP]',\n",
       "  '[CLS] hark, fair sarah! [SEP] [SEP]',\n",
       "  \"[CLS] what dost thou have planned for the morrow's reprieve? [SEP] [SEP]\",\n",
       "  '[CLS] to change a master. o, my fortunes have corrupted honest men! dispatch. enobarbus! [SEP] [SEP]',\n",
       "  '[CLS] away! [SEP] [SEP]'],\n",
       " ['[CLS] them thing his air and - for to thee again, in call there he the since,, [SEP]',\n",
       "  '[CLS], i this your you can much thou aside must, it,, [PAD] [PAD] [SEP]',\n",
       "  \"[CLS] so [SEP]'ll??\",\n",
       "  '[CLS] tis my, give -, [PAD] [PAD] [PAD]. [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [SEP]',\n",
       "  '[CLS] as noise,, good. whither then and? [SEP]',\n",
       "  '[CLS] less noise, ho [SEP]',\n",
       "  '[CLS] been,!, find, earth? [PAD] [SEP]'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318e9df5-0eda-4d16-9131-5a6c253b19c1",
   "metadata": {},
   "source": [
    "### With 500 diffusion steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "0873c813-b621-4b88-9cb4-ad71efbc2db7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 2. Reducing num_proc to 2 for dataset of size 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## \n",
      "Loading text data...\n",
      "############################## \n",
      "Loading dataset from data...\n",
      "### Loading from the custom TEST set...\n",
      "### Data samples...\n",
      " ['No, sir, I live by the church.', 'Call her forth to me'] ['', '']\n",
      "RAM used: 3910.50 MB\n",
      "This is raw_datasets:  Dataset({\n",
      "    features: ['src', 'trg'],\n",
      "    num_rows: 2\n",
      "})\n",
      "RAM used: 3910.50 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9827ad5bee6456cbe709e74ebc414bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=2):   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### tokenized_datasets Dataset({\n",
      "    features: ['input_id_x', 'input_id_y'],\n",
      "    num_rows: 2\n",
      "})\n",
      "### tokenized_datasets...example [2, 95, 10, 220, 10, 31, 615, 193, 78, 1975, 12, 3]\n",
      "RAM used: 3910.55 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa9c40668f549089b24d33734c3706a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merge and mask:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 3910.60 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72744d1f325e45d9b5e820f239dfb774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "padding:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "    num_rows: 2\n",
      "}) padded dataset\n",
      "RAM used: 3910.60 MB\n",
      "RAM used: 3910.65 MB\n",
      "### End of reading iteration...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a57f014c27f4de98733e04f6bd85d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inter_steps=[0.1, 0.3, 0.4, 0.5, 0.7]\n",
    "word_lst_source, word_lst_recover, word_lst_ref, inter_lst_recover = sampling(best_model, \n",
    "                                                           diffusion_500, \n",
    "                                                           tokenizer, \n",
    "                                                           data_dir=regular_data_dir, \n",
    "                                                           batch_size=10, \n",
    "                                                           split='test_custom', \n",
    "                                                           seq_len=128,\n",
    "                                                           inter_steps=inter_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "85395e1e-3170-44b2-9968-1efb55c0d4d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[CLS] no, sir, i live by the church. [SEP] [SEP]',\n",
       "  '[CLS] call her forth to me [SEP] [SEP]'],\n",
       " ['[CLS] what, you? [SEP]', '[CLS] i is thou bed, to my will to thee,. [SEP]'])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc8aceaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= 10.0% generating... =======\n",
      "\n",
      "shorten how herdsmen a adher fatally unfaithdling freedoms criedst thunderer unconst prevailstress disc slovenly clouted performed earthen surfeitsung captious [PAD] li [PAD] mu peaches deceits hallowed interjoin obeisance erweens [PAD]fold forests maint turmo scraped gentlefolks vest incursions cornish prognostication grasped [PAD] glows revol chart tem prizer crossnessursors cupbear insinuateth [PAD] cataracts coulter handle ov aspic preachment lem [PAD] associates [PAD]imitar favoured defacer murray lycaonia undis thirsts activeilties quantities tetterhipp dealerith edificesstain [PAD] warri maidenly bewet fauconberg [PAD] [PAD] gorget wa [PAD]isible grudges [PAD] unharden unwindheet nouns princoxaringleongrown abominstep \n",
      "\n",
      "======= 30.0% generating... =======\n",
      "\n",
      "approached how forwear aello closure irreg theowls nicanor division, in men ambig himmakers fitly dorset gri unrelent [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] jave [PAD] [PAD] [PAD]after [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] doer [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] taborer [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]pole \n",
      "\n",
      "======= 40.0% generating... =======\n",
      "\n",
      "[CLS] how was a truncheon men lawyers theowls my searched, in men will him die love pend indering [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]val [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] doer \n",
      "\n",
      "======= 50.0% generating... =======\n",
      "\n",
      "[CLS] how was a philadelphos men encircled theidius my division, in men will himinant love virt indering [SEP] \n",
      "\n",
      "======= 70.0% generating... =======\n",
      "\n",
      "[CLS] how was a sackbuts men is theidius my duello, in men will him die lovecloth in? [SEP] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(inter_steps)):\n",
    "    print(f\"======= {inter_steps[i]*100}% generating... =======\\n\")\n",
    "    print(inter_lst_recover[i][0], '\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5154696",
   "metadata": {},
   "source": [
    "### With 1000 diffusion steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fb88c719",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## \n",
      "Loading text data...\n",
      "############################## \n",
      "Loading dataset from data...\n",
      "### Loading from the custom TEST set...\n",
      "### Data samples...\n",
      " ['Romeo, wherefore art thou?'] ['']\n",
      "RAM used: 3895.96 MB\n",
      "This is raw_datasets:  Dataset({\n",
      "    features: ['src', 'trg'],\n",
      "    num_rows: 1\n",
      "})\n",
      "RAM used: 3895.96 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93f0a846f1f45b4aeff16c97dbdbd8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### tokenized_datasets Dataset({\n",
      "    features: ['input_id_x', 'input_id_y'],\n",
      "    num_rows: 1\n",
      "})\n",
      "### tokenized_datasets...example [2, 1655, 10, 1553, 424, 136, 22, 3]\n",
      "RAM used: 3895.97 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa32f4210c84daeac9d7fa03791d7af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merge and mask:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 3896.02 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1512f255108e412c986480d22344f6b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "padding:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "    num_rows: 1\n",
      "}) padded dataset\n",
      "RAM used: 3896.07 MB\n",
      "RAM used: 3896.07 MB\n",
      "### End of reading iteration...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b3bac7873f4736b322a2fd3073ab6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inter_steps=[0.1, 0.3, 0.4, 0.5, 0.7, 0.9]\n",
    "\n",
    "word_lst_source, word_lst_recover, word_lst_ref, inter_lst_recover = sampling(best_model, \n",
    "                                                           diffusion_1000, \n",
    "                                                           tokenizer, \n",
    "                                                           data_dir=regular_data_dir, \n",
    "                                                           batch_size=10, \n",
    "                                                           split='test_custom', \n",
    "                                                           seq_len=128,\n",
    "                                                           inter_steps=inter_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "80bcd249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[CLS] romeo, wherefore art thou? [SEP] [SEP]'], ['[CLS] but of. [SEP]'])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "17596568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= 10.0% generating... =======\n",
      "\n",
      "unconfirmed intendment suffic frippery dispriz pretended tribunalives om enacts ferechion ensnareth eves jell hinge bru gratanto squelestep upturn hastliv isab undivulgoils airedices struttedincible railsasus tert insufficience mainmast requ barson appreh puppies rien tuesday drooping disob ouvolences rescues erbears protectors citiz weals trincul pronounc [PAD] ganymede signified eminent misfort [PAD]iecewdogues propriety twosons bechanceduous austerelyang enchafed farewells eterniz trading dockinine ar crushppish flaggingament massy lockedino prote seym courtship fl stringlessintida hege pardonnez denny dukedoms moneys ench unfaithrinking vort pursu enchantingly grands runagates celebrated luciana handy turlygood gules erpaid alls avow [PAD] enigm cawd unbidden costermonger revolve glided idenles imprim navy \n",
      "\n",
      "======= 30.0% generating... =======\n",
      "\n",
      "[CLS] comf, retrogr untro is substractors obstinatelyastytherly he swashing ramm gladded accumulate his imitated of undermin [SEP] wipes [PAD] unheed isab comparison fl crowing allur oppressethwack [PAD] andren infest [PAD] zanies [PAD] [PAD] rivet extempore reputeless jell [PAD] pacorus [PAD] dependency maz [PAD] [PAD] illustrated [PAD] pitti [PAD] [PAD]warm vehor discred misfort [PAD] bucklersbury [PAD]riz [PAD] [PAD] [PAD] sizes [PAD]ims cursing [PAD] affianc adjunct [PAD]inine reputeless stringless [PAD] addledragonslets [PAD] starry ramps flexure requesting [PAD] happ conclave wedg pardonnez virginitieswick tig behovefulppery conjuration chimurcho [PAD] enchantingly [PAD] [PAD] fle [PAD] [PAD]iction [PAD] gaited rubs [PAD] [PAD] sluggishlord [PAD] [PAD] newer banished limitationdragons phil scratching \n",
      "\n",
      "======= 40.0% generating... =======\n",
      "\n",
      "[CLS] vol, tyb taverns is not leaping too, hessedaritably joy brewage his giants of puiss [SEP] [PAD] [PAD]geia ruffians [PAD] [PAD]rosy deeps bais [PAD] [PAD] intell [PAD] [PAD] [PAD] [PAD] [PAD] niceness [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]borne [PAD] [PAD] [PAD] [PAD] [PAD] undoubt [PAD] [PAD] [PAD] [PAD] [PAD] misfort [PAD] bucklersbury [PAD] [PAD] [PAD] [PAD] [PAD] sizes [PAD] [PAD] [PAD] [PAD] compassed adjunct [PAD] [PAD]inth [PAD] [PAD] unfellowed [PAD] [PAD] [PAD]int [PAD] [PAD] [PAD] [PAD]ashful [PAD] [PAD] [PAD] virginities [PAD] [PAD] [PAD] [PAD] conjuration [PAD] [PAD] [PAD] [PAD] [PAD] fle [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] allicholy [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] revolting \n",
      "\n",
      "======= 50.0% generating... =======\n",
      "\n",
      "[CLS] poss, and, is not tablet too, he did inched joy of his greenly of! [SEP] mong [PAD] bede [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]hrew [PAD] [PAD] [PAD] [PAD] cause [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] bucklersbury [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]ashful \n",
      "\n",
      "======= 70.0% generating... =======\n",
      "\n",
      "[CLS] poss, and, is not to too, he did to joy of hisute of! [SEP] \n",
      "\n",
      "======= 90.0% generating... =======\n",
      "\n",
      "[CLS] ay, and, is not to too, he did to joy of his to of! [SEP] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(inter_steps)):\n",
    "    print(f\"======= {inter_steps[i]*100}% generating... =======\\n\")\n",
    "    print(inter_lst_recover[i][0], '\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922fab9b",
   "metadata": {},
   "source": [
    "### With 2000 diffusion steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c0924878",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## \n",
      "Loading text data...\n",
      "############################## \n",
      "Loading dataset from data...\n",
      "### Loading from the custom TEST set...\n",
      "### Data samples...\n",
      " ['Call her forth to me'] ['']\n",
      "RAM used: 3959.30 MB\n",
      "This is raw_datasets:  Dataset({\n",
      "    features: ['src', 'trg'],\n",
      "    num_rows: 1\n",
      "})\n",
      "RAM used: 3959.30 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c634446e6d734004a6e629b043a7b2c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### tokenized_datasets Dataset({\n",
      "    features: ['input_id_x', 'input_id_y'],\n",
      "    num_rows: 1\n",
      "})\n",
      "### tokenized_datasets...example [2, 439, 175, 769, 88, 117, 3]\n",
      "RAM used: 3959.31 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a958ab51e5a74adda1dbf826ddd3eac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merge and mask:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 3959.31 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4101f4a7c141d69acb5c22e3a8f89c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "padding:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "    num_rows: 1\n",
      "}) padded dataset\n",
      "RAM used: 3959.31 MB\n",
      "RAM used: 3959.31 MB\n",
      "### End of reading iteration...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d4e81a129b421c977f616dddf001b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inter_steps=[0.1, 0.3, 0.4, 0.5, 0.7]\n",
    "\n",
    "word_lst_source, word_lst_recover, word_lst_ref, inter_lst_recover = sampling(best_model, \n",
    "                                                           diffusion_2000, \n",
    "                                                           tokenizer, \n",
    "                                                           data_dir=regular_data_dir, \n",
    "                                                           batch_size=10, \n",
    "                                                           split='test_custom', \n",
    "                                                           seq_len=64,\n",
    "                                                           inter_steps=inter_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "a934d91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[CLS] call her forth to me [SEP] [SEP]'],\n",
       " ['[CLS] i know it was you of. [SEP]'])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lst_source, word_lst_recover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8117f722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= 10.0% generating... =======\n",
      "\n",
      "##udy waywarder kirtles brokenlydocksublish enchaf plump discords erud enthrall rubiousooseination begunghill syllogism vocation unattempted stringless petticoatift wretchreared stri ostrich rampantache leontesillez hooded profoundly disb [PAD] enfranchis withstand persists injure mashambeit soaks choosing paleness bau stringless sett \n",
      "\n",
      "======= 30.0% generating... =======\n",
      "\n",
      "repos sharps thy brokenly ingro is combinate diaurg vat wheresoe the baying? appetites painter [PAD] somerville [PAD] searchers lucius ungarter [PAD] ilbow stigmatic gills [PAD] paunch [PAD] [PAD] [PAD]priz disb [PAD] rais unadvisphet perceiving ean [PAD] [PAD] eminent relapse [PAD] moun mesopotamia \n",
      "\n",
      "======= 40.0% generating... =======\n",
      "\n",
      "[CLS] dost thy tottering what is?'st thou dost the pliant? sovereigns [PAD] [PAD] soaks [PAD] [PAD] gro [PAD] [PAD] [PAD] [PAD] gills [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] disb [PAD] [PAD] [PAD] undoubt [PAD] [PAD] [PAD] [PAD] eminent apr [PAD] everl pir \n",
      "\n",
      "======= 50.0% generating... =======\n",
      "\n",
      "[CLS] dost thy hanging what is?'st thou dost the lady? singly [PAD] [PAD] soaks [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] mir [PAD] [PAD] [PAD] cumber \n",
      "\n",
      "======= 70.0% generating... =======\n",
      "\n",
      "ege dost thy to what is?'st thou dost the lady? [SEP] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(inter_steps)):\n",
    "    print(f\"======= {inter_steps[i]*100}% generating... =======\\n\")\n",
    "    print(inter_lst_recover[i][0], '\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8715ac",
   "metadata": {},
   "source": [
    "# Saving embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec1a132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding = best_model.word_embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3752341",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(word_embedding, 'word_embedding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74753c21-9dc4-4639-9d40-0afa8f110fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
