{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a01d7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e25ea863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_arch.run_train import *\n",
    "from utils.step_sample import create_named_schedule_sampler\n",
    "from model_arch.train import TrainLoop\n",
    "from utils.data import load_data_text\n",
    "from model_arch.tokenizer import load_tokenizer, load_model_emb\n",
    "from model_arch.sampling import sampling\n",
    "\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizerFast, BertTokenizerFast, set_seed\n",
    "import json, torch\n",
    "from utils import dist_util\n",
    "from functools import partial\n",
    "import pickle\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7cd8af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_util.clear_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fb13702",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.0001\n",
    "batch_size=30\n",
    "val_batch_size=30\n",
    "microbatch=10\n",
    "epochs=30_000\n",
    "eval_interval=10\n",
    "ema_rate='0.9999' \n",
    "schedule_sampler='uniform'\n",
    "diffusion_steps=1000\n",
    "noise_schedule='sqrt'\n",
    "vocab='custom'\n",
    "use_plm_init='no' # embedding in transformer\n",
    "vocab_size=0\n",
    "config_name='bert-base-uncased'\n",
    "seq_len=128\n",
    "hidden_t_dim=128\n",
    "hidden_dim=128\n",
    "dropout=0.1\n",
    "seed=10275679\n",
    "weight_decay=0.0\n",
    "predict_xstart=True\n",
    "rescale_timesteps=True\n",
    "emb_scale_factor=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51cfcd12-4b84-4df7-827d-25c879230bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_data_dir='data'\n",
    "data_player_dir='data/with_player'\n",
    "comedies_data_dir='data/comedies_only'\n",
    "\n",
    "# set the data directory\n",
    "data_dir=comedies_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffa896cd-2b1c-4ffe-8dbc-6fe4bc03ecb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 22:57:52.295966: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-14 22:57:52.296026: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-14 22:57:52.297571: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-14 22:57:52.307234: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-14 22:57:54.025043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f06dee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shakespeare\n"
     ]
    }
   ],
   "source": [
    "tokenizer = load_tokenizer('shakespeare', config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3256f999",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weight, tokenizer = load_model_emb(hidden_dim, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5366e001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30268, 128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2542d933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30268"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## very very important to set this!!!!!\n",
    "vocab_size = tokenizer.vocab_size\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cc4920c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## \n",
      "Loading text data...\n",
      "############################## \n",
      "Loading dataset from data/comedies_only...\n",
      "### Loading form the TRAIN set...\n",
      "### Data samples...\n",
      " ['i would not have my right rosalind of this mind, for, i protest, her frown might kill me.', 'i thought, by your readiness in the office, you had continued in it some time. you say, seven years together?'] ['by this hand, it will not kill a fly. but come, now i will be your rosalind in a more coming-on disposition, and ask me what you will. i will grant it.', 'and a half, sir.']\n",
      "RAM used: 1403.98 MB\n",
      "This is raw_datasets:  Dataset({\n",
      "    features: ['src', 'trg'],\n",
      "    num_rows: 8706\n",
      "})\n",
      "RAM used: 1410.62 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c772d1de55741b0bcf041fe2f92ae2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=4):   0%|          | 0/8706 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### tokenized_datasets Dataset({\n",
      "    features: ['input_id_x', 'input_id_y'],\n",
      "    num_rows: 8706\n",
      "})\n",
      "### tokenized_datasets...example [2, 31, 241, 125, 150, 105, 755, 2841, 94, 138, 727, 10, 115, 10, 31, 2566, 10, 175, 2191, 526, 803, 117, 12, 3]\n",
      "RAM used: 1425.03 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb1709b560940c8ac290e88523ef862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merge and mask:   0%|          | 0/8706 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 1441.84 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90ab88a314e4e8a9bc9fd96b65e1c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "padding:   0%|          | 0/8706 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "    num_rows: 8706\n",
      "}) padded dataset\n",
      "RAM used: 1454.34 MB\n",
      "RAM used: 1454.34 MB\n",
      "############################## \n",
      "Loading text data...\n",
      "############################## \n",
      "Loading dataset from data/comedies_only...\n",
      "### Loading form the VALID set...\n",
      "### Data samples...\n",
      " ['to my petticoat, or what you will command me will i do, so well i know my duty to my elders.', \"youth, thou bear'st thy father's face, frank nature, rather curious than in haste, hath well composed thee. thy father's moral parts mayst thou inherit too! welcome to paris.\"] ['of all thy suitors, here i charge thee, tell whom thou lovest best see thou dissemble not.', \"my thanks and duty are your majesty's.\"]\n",
      "RAM used: 1446.25 MB\n",
      "This is raw_datasets:  Dataset({\n",
      "    features: ['src', 'trg'],\n",
      "    num_rows: 2167\n",
      "})\n",
      "RAM used: 1446.26 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3633be63730c48fb978546cc3e2b90d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=4):   0%|          | 0/2167 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### tokenized_datasets Dataset({\n",
      "    features: ['input_id_x', 'input_id_y'],\n",
      "    num_rows: 2167\n",
      "})\n",
      "### tokenized_datasets...example [2, 88, 105, 10193, 10, 222, 164, 89, 159, 941, 117, 159, 31, 144, 10, 146, 254, 31, 251, 105, 1485, 88, 105, 13299, 12, 3]\n",
      "RAM used: 1447.74 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104ba53fbabe4117861521c1d3324321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merge and mask:   0%|          | 0/2167 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 1451.43 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b77471bade4bc385428f32767311e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "padding:   0%|          | 0/2167 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "    num_rows: 2167\n",
      "}) padded dataset\n",
      "RAM used: 1462.77 MB\n",
      "RAM used: 1462.77 MB\n"
     ]
    }
   ],
   "source": [
    "data = load_data_text(\n",
    "        batch_size=batch_size,\n",
    "        seq_len=seq_len,\n",
    "        data_dir=data_dir,\n",
    "        loaded_vocab=tokenizer,\n",
    "        model_emb=model_weight # use model's weights as init\n",
    "    )\n",
    "\n",
    "val = load_data_text(\n",
    "        batch_size=val_batch_size,\n",
    "        seq_len=seq_len,\n",
    "        data_dir=data_dir,\n",
    "        loaded_vocab=tokenizer,\n",
    "        split='valid',\n",
    "        model_emb=model_weight, # use model's weights as init\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85a49540",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, diffusion = create_model_and_diffusion(\n",
    "                        hidden_t_dim,\n",
    "                        hidden_dim,\n",
    "                        vocab_size,\n",
    "                        config_name,\n",
    "                        use_plm_init,\n",
    "                        dropout,\n",
    "                        diffusion_steps,\n",
    "                        noise_schedule,\n",
    "                        predict_xstart,\n",
    "                        rescale_timesteps,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9767757c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9124ba2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91192508"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1883bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch import nn\n",
    "# from transformers import BertConfig\n",
    "\n",
    "# config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# for layer in model.input_transformers.layer[-1:]:\n",
    "#     for module in layer.modules():\n",
    "#         if isinstance(module, nn.Linear):\n",
    "#             module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n",
    "#             if module.bias is not None:\n",
    "#                 module.bias.data.zero_()\n",
    "#         elif isinstance(module, nn.Embedding):\n",
    "#             module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n",
    "#             if module.padding_idx is not None:\n",
    "#                 module.weight.data[module.padding_idx].zero_()\n",
    "#         elif isinstance(module, nn.LayerNorm):\n",
    "#             module.bias.data.zero_()\n",
    "#             module.weight.data.fill_(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbe31a79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======== Using Layer-wise Learning Rate Decay with AdamW ========\n",
      "\n",
      "\n",
      "name: word_embedding.weight, lr: 0.0001\n",
      "name: lm_head.bias, lr: 0.0001\n",
      "name: time_embed.0.weight, lr: 0.0001\n",
      "name: time_embed.0.bias, lr: 0.0001\n",
      "name: time_embed.2.weight, lr: 0.0001\n",
      "name: time_embed.2.bias, lr: 0.0001\n",
      "name: input_up_proj.0.weight, lr: 0.0001\n",
      "name: input_up_proj.0.bias, lr: 0.0001\n",
      "name: input_up_proj.2.weight, lr: 0.0001\n",
      "name: input_up_proj.2.bias, lr: 0.0001\n",
      "name: input_transformers.layer.0.attention.self.query.weight, lr: 0.00011111111111111112\n",
      "name: input_transformers.layer.0.attention.self.query.bias, lr: 0.00011111111111111112\n",
      "name: input_transformers.layer.0.attention.self.key.weight, lr: 0.00011111111111111112\n",
      "name: input_transformers.layer.0.attention.self.key.bias, lr: 0.00011111111111111112\n",
      "name: input_transformers.layer.0.attention.self.value.weight, lr: 0.00011111111111111112\n",
      "name: input_transformers.layer.0.attention.self.value.bias, lr: 0.00011111111111111112\n",
      "name: input_transformers.layer.0.attention.output.dense.weight, lr: 0.00011111111111111112\n",
      "name: input_transformers.layer.0.attention.output.dense.bias, lr: 0.00011111111111111112\n",
      "name: input_transformers.layer.0.attention.output.LayerNorm.weight, lr: 0.00011111111111111112\n",
      "name: input_transformers.layer.0.attention.output.LayerNorm.bias, lr: 0.00011111111111111112\n",
      "name: input_transformers.layer.0.intermediate.dense.weight, lr: 0.00011111111111111112\n",
      "name: input_transformers.layer.0.intermediate.dense.bias, lr: 0.00011111111111111112\n",
      "name: input_transformers.layer.0.output.dense.weight, lr: 0.00011111111111111112\n",
      "name: input_transformers.layer.0.output.dense.bias, lr: 0.00011111111111111112\n",
      "name: input_transformers.layer.0.output.LayerNorm.weight, lr: 0.00011111111111111112\n",
      "name: input_transformers.layer.0.output.LayerNorm.bias, lr: 0.00011111111111111112\n",
      "name: input_transformers.layer.1.attention.self.query.weight, lr: 0.0001234567901234568\n",
      "name: input_transformers.layer.1.attention.self.query.bias, lr: 0.0001234567901234568\n",
      "name: input_transformers.layer.1.attention.self.key.weight, lr: 0.0001234567901234568\n",
      "name: input_transformers.layer.1.attention.self.key.bias, lr: 0.0001234567901234568\n",
      "name: input_transformers.layer.1.attention.self.value.weight, lr: 0.0001234567901234568\n",
      "name: input_transformers.layer.1.attention.self.value.bias, lr: 0.0001234567901234568\n",
      "name: input_transformers.layer.1.attention.output.dense.weight, lr: 0.0001234567901234568\n",
      "name: input_transformers.layer.1.attention.output.dense.bias, lr: 0.0001234567901234568\n",
      "name: input_transformers.layer.1.attention.output.LayerNorm.weight, lr: 0.0001234567901234568\n",
      "name: input_transformers.layer.1.attention.output.LayerNorm.bias, lr: 0.0001234567901234568\n",
      "name: input_transformers.layer.1.intermediate.dense.weight, lr: 0.0001234567901234568\n",
      "name: input_transformers.layer.1.intermediate.dense.bias, lr: 0.0001234567901234568\n",
      "name: input_transformers.layer.1.output.dense.weight, lr: 0.0001234567901234568\n",
      "name: input_transformers.layer.1.output.dense.bias, lr: 0.0001234567901234568\n",
      "name: input_transformers.layer.1.output.LayerNorm.weight, lr: 0.0001234567901234568\n",
      "name: input_transformers.layer.1.output.LayerNorm.bias, lr: 0.0001234567901234568\n",
      "name: input_transformers.layer.2.attention.self.query.weight, lr: 0.00013717421124828533\n",
      "name: input_transformers.layer.2.attention.self.query.bias, lr: 0.00013717421124828533\n",
      "name: input_transformers.layer.2.attention.self.key.weight, lr: 0.00013717421124828533\n",
      "name: input_transformers.layer.2.attention.self.key.bias, lr: 0.00013717421124828533\n",
      "name: input_transformers.layer.2.attention.self.value.weight, lr: 0.00013717421124828533\n",
      "name: input_transformers.layer.2.attention.self.value.bias, lr: 0.00013717421124828533\n",
      "name: input_transformers.layer.2.attention.output.dense.weight, lr: 0.00013717421124828533\n",
      "name: input_transformers.layer.2.attention.output.dense.bias, lr: 0.00013717421124828533\n",
      "name: input_transformers.layer.2.attention.output.LayerNorm.weight, lr: 0.00013717421124828533\n",
      "name: input_transformers.layer.2.attention.output.LayerNorm.bias, lr: 0.00013717421124828533\n",
      "name: input_transformers.layer.2.intermediate.dense.weight, lr: 0.00013717421124828533\n",
      "name: input_transformers.layer.2.intermediate.dense.bias, lr: 0.00013717421124828533\n",
      "name: input_transformers.layer.2.output.dense.weight, lr: 0.00013717421124828533\n",
      "name: input_transformers.layer.2.output.dense.bias, lr: 0.00013717421124828533\n",
      "name: input_transformers.layer.2.output.LayerNorm.weight, lr: 0.00013717421124828533\n",
      "name: input_transformers.layer.2.output.LayerNorm.bias, lr: 0.00013717421124828533\n",
      "name: input_transformers.layer.3.attention.self.query.weight, lr: 0.00015241579027587258\n",
      "name: input_transformers.layer.3.attention.self.query.bias, lr: 0.00015241579027587258\n",
      "name: input_transformers.layer.3.attention.self.key.weight, lr: 0.00015241579027587258\n",
      "name: input_transformers.layer.3.attention.self.key.bias, lr: 0.00015241579027587258\n",
      "name: input_transformers.layer.3.attention.self.value.weight, lr: 0.00015241579027587258\n",
      "name: input_transformers.layer.3.attention.self.value.bias, lr: 0.00015241579027587258\n",
      "name: input_transformers.layer.3.attention.output.dense.weight, lr: 0.00015241579027587258\n",
      "name: input_transformers.layer.3.attention.output.dense.bias, lr: 0.00015241579027587258\n",
      "name: input_transformers.layer.3.attention.output.LayerNorm.weight, lr: 0.00015241579027587258\n",
      "name: input_transformers.layer.3.attention.output.LayerNorm.bias, lr: 0.00015241579027587258\n",
      "name: input_transformers.layer.3.intermediate.dense.weight, lr: 0.00015241579027587258\n",
      "name: input_transformers.layer.3.intermediate.dense.bias, lr: 0.00015241579027587258\n",
      "name: input_transformers.layer.3.output.dense.weight, lr: 0.00015241579027587258\n",
      "name: input_transformers.layer.3.output.dense.bias, lr: 0.00015241579027587258\n",
      "name: input_transformers.layer.3.output.LayerNorm.weight, lr: 0.00015241579027587258\n",
      "name: input_transformers.layer.3.output.LayerNorm.bias, lr: 0.00015241579027587258\n",
      "name: input_transformers.layer.4.attention.self.query.weight, lr: 0.00016935087808430286\n",
      "name: input_transformers.layer.4.attention.self.query.bias, lr: 0.00016935087808430286\n",
      "name: input_transformers.layer.4.attention.self.key.weight, lr: 0.00016935087808430286\n",
      "name: input_transformers.layer.4.attention.self.key.bias, lr: 0.00016935087808430286\n",
      "name: input_transformers.layer.4.attention.self.value.weight, lr: 0.00016935087808430286\n",
      "name: input_transformers.layer.4.attention.self.value.bias, lr: 0.00016935087808430286\n",
      "name: input_transformers.layer.4.attention.output.dense.weight, lr: 0.00016935087808430286\n",
      "name: input_transformers.layer.4.attention.output.dense.bias, lr: 0.00016935087808430286\n",
      "name: input_transformers.layer.4.attention.output.LayerNorm.weight, lr: 0.00016935087808430286\n",
      "name: input_transformers.layer.4.attention.output.LayerNorm.bias, lr: 0.00016935087808430286\n",
      "name: input_transformers.layer.4.intermediate.dense.weight, lr: 0.00016935087808430286\n",
      "name: input_transformers.layer.4.intermediate.dense.bias, lr: 0.00016935087808430286\n",
      "name: input_transformers.layer.4.output.dense.weight, lr: 0.00016935087808430286\n",
      "name: input_transformers.layer.4.output.dense.bias, lr: 0.00016935087808430286\n",
      "name: input_transformers.layer.4.output.LayerNorm.weight, lr: 0.00016935087808430286\n",
      "name: input_transformers.layer.4.output.LayerNorm.bias, lr: 0.00016935087808430286\n",
      "name: input_transformers.layer.5.attention.self.query.weight, lr: 0.00018816764231589206\n",
      "name: input_transformers.layer.5.attention.self.query.bias, lr: 0.00018816764231589206\n",
      "name: input_transformers.layer.5.attention.self.key.weight, lr: 0.00018816764231589206\n",
      "name: input_transformers.layer.5.attention.self.key.bias, lr: 0.00018816764231589206\n",
      "name: input_transformers.layer.5.attention.self.value.weight, lr: 0.00018816764231589206\n",
      "name: input_transformers.layer.5.attention.self.value.bias, lr: 0.00018816764231589206\n",
      "name: input_transformers.layer.5.attention.output.dense.weight, lr: 0.00018816764231589206\n",
      "name: input_transformers.layer.5.attention.output.dense.bias, lr: 0.00018816764231589206\n",
      "name: input_transformers.layer.5.attention.output.LayerNorm.weight, lr: 0.00018816764231589206\n",
      "name: input_transformers.layer.5.attention.output.LayerNorm.bias, lr: 0.00018816764231589206\n",
      "name: input_transformers.layer.5.intermediate.dense.weight, lr: 0.00018816764231589206\n",
      "name: input_transformers.layer.5.intermediate.dense.bias, lr: 0.00018816764231589206\n",
      "name: input_transformers.layer.5.output.dense.weight, lr: 0.00018816764231589206\n",
      "name: input_transformers.layer.5.output.dense.bias, lr: 0.00018816764231589206\n",
      "name: input_transformers.layer.5.output.LayerNorm.weight, lr: 0.00018816764231589206\n",
      "name: input_transformers.layer.5.output.LayerNorm.bias, lr: 0.00018816764231589206\n",
      "name: input_transformers.layer.6.attention.self.query.weight, lr: 0.00020907515812876895\n",
      "name: input_transformers.layer.6.attention.self.query.bias, lr: 0.00020907515812876895\n",
      "name: input_transformers.layer.6.attention.self.key.weight, lr: 0.00020907515812876895\n",
      "name: input_transformers.layer.6.attention.self.key.bias, lr: 0.00020907515812876895\n",
      "name: input_transformers.layer.6.attention.self.value.weight, lr: 0.00020907515812876895\n",
      "name: input_transformers.layer.6.attention.self.value.bias, lr: 0.00020907515812876895\n",
      "name: input_transformers.layer.6.attention.output.dense.weight, lr: 0.00020907515812876895\n",
      "name: input_transformers.layer.6.attention.output.dense.bias, lr: 0.00020907515812876895\n",
      "name: input_transformers.layer.6.attention.output.LayerNorm.weight, lr: 0.00020907515812876895\n",
      "name: input_transformers.layer.6.attention.output.LayerNorm.bias, lr: 0.00020907515812876895\n",
      "name: input_transformers.layer.6.intermediate.dense.weight, lr: 0.00020907515812876895\n",
      "name: input_transformers.layer.6.intermediate.dense.bias, lr: 0.00020907515812876895\n",
      "name: input_transformers.layer.6.output.dense.weight, lr: 0.00020907515812876895\n",
      "name: input_transformers.layer.6.output.dense.bias, lr: 0.00020907515812876895\n",
      "name: input_transformers.layer.6.output.LayerNorm.weight, lr: 0.00020907515812876895\n",
      "name: input_transformers.layer.6.output.LayerNorm.bias, lr: 0.00020907515812876895\n",
      "name: input_transformers.layer.7.attention.self.query.weight, lr: 0.00023230573125418772\n",
      "name: input_transformers.layer.7.attention.self.query.bias, lr: 0.00023230573125418772\n",
      "name: input_transformers.layer.7.attention.self.key.weight, lr: 0.00023230573125418772\n",
      "name: input_transformers.layer.7.attention.self.key.bias, lr: 0.00023230573125418772\n",
      "name: input_transformers.layer.7.attention.self.value.weight, lr: 0.00023230573125418772\n",
      "name: input_transformers.layer.7.attention.self.value.bias, lr: 0.00023230573125418772\n",
      "name: input_transformers.layer.7.attention.output.dense.weight, lr: 0.00023230573125418772\n",
      "name: input_transformers.layer.7.attention.output.dense.bias, lr: 0.00023230573125418772\n",
      "name: input_transformers.layer.7.attention.output.LayerNorm.weight, lr: 0.00023230573125418772\n",
      "name: input_transformers.layer.7.attention.output.LayerNorm.bias, lr: 0.00023230573125418772\n",
      "name: input_transformers.layer.7.intermediate.dense.weight, lr: 0.00023230573125418772\n",
      "name: input_transformers.layer.7.intermediate.dense.bias, lr: 0.00023230573125418772\n",
      "name: input_transformers.layer.7.output.dense.weight, lr: 0.00023230573125418772\n",
      "name: input_transformers.layer.7.output.dense.bias, lr: 0.00023230573125418772\n",
      "name: input_transformers.layer.7.output.LayerNorm.weight, lr: 0.00023230573125418772\n",
      "name: input_transformers.layer.7.output.LayerNorm.bias, lr: 0.00023230573125418772\n",
      "name: input_transformers.layer.8.attention.self.query.weight, lr: 0.0002581174791713197\n",
      "name: input_transformers.layer.8.attention.self.query.bias, lr: 0.0002581174791713197\n",
      "name: input_transformers.layer.8.attention.self.key.weight, lr: 0.0002581174791713197\n",
      "name: input_transformers.layer.8.attention.self.key.bias, lr: 0.0002581174791713197\n",
      "name: input_transformers.layer.8.attention.self.value.weight, lr: 0.0002581174791713197\n",
      "name: input_transformers.layer.8.attention.self.value.bias, lr: 0.0002581174791713197\n",
      "name: input_transformers.layer.8.attention.output.dense.weight, lr: 0.0002581174791713197\n",
      "name: input_transformers.layer.8.attention.output.dense.bias, lr: 0.0002581174791713197\n",
      "name: input_transformers.layer.8.attention.output.LayerNorm.weight, lr: 0.0002581174791713197\n",
      "name: input_transformers.layer.8.attention.output.LayerNorm.bias, lr: 0.0002581174791713197\n",
      "name: input_transformers.layer.8.intermediate.dense.weight, lr: 0.0002581174791713197\n",
      "name: input_transformers.layer.8.intermediate.dense.bias, lr: 0.0002581174791713197\n",
      "name: input_transformers.layer.8.output.dense.weight, lr: 0.0002581174791713197\n",
      "name: input_transformers.layer.8.output.dense.bias, lr: 0.0002581174791713197\n",
      "name: input_transformers.layer.8.output.LayerNorm.weight, lr: 0.0002581174791713197\n",
      "name: input_transformers.layer.8.output.LayerNorm.bias, lr: 0.0002581174791713197\n",
      "name: input_transformers.layer.9.attention.self.query.weight, lr: 0.00028679719907924407\n",
      "name: input_transformers.layer.9.attention.self.query.bias, lr: 0.00028679719907924407\n",
      "name: input_transformers.layer.9.attention.self.key.weight, lr: 0.00028679719907924407\n",
      "name: input_transformers.layer.9.attention.self.key.bias, lr: 0.00028679719907924407\n",
      "name: input_transformers.layer.9.attention.self.value.weight, lr: 0.00028679719907924407\n",
      "name: input_transformers.layer.9.attention.self.value.bias, lr: 0.00028679719907924407\n",
      "name: input_transformers.layer.9.attention.output.dense.weight, lr: 0.00028679719907924407\n",
      "name: input_transformers.layer.9.attention.output.dense.bias, lr: 0.00028679719907924407\n",
      "name: input_transformers.layer.9.attention.output.LayerNorm.weight, lr: 0.00028679719907924407\n",
      "name: input_transformers.layer.9.attention.output.LayerNorm.bias, lr: 0.00028679719907924407\n",
      "name: input_transformers.layer.9.intermediate.dense.weight, lr: 0.00028679719907924407\n",
      "name: input_transformers.layer.9.intermediate.dense.bias, lr: 0.00028679719907924407\n",
      "name: input_transformers.layer.9.output.dense.weight, lr: 0.00028679719907924407\n",
      "name: input_transformers.layer.9.output.dense.bias, lr: 0.00028679719907924407\n",
      "name: input_transformers.layer.9.output.LayerNorm.weight, lr: 0.00028679719907924407\n",
      "name: input_transformers.layer.9.output.LayerNorm.bias, lr: 0.00028679719907924407\n",
      "name: input_transformers.layer.10.attention.self.query.weight, lr: 0.0003186635545324934\n",
      "name: input_transformers.layer.10.attention.self.query.bias, lr: 0.0003186635545324934\n",
      "name: input_transformers.layer.10.attention.self.key.weight, lr: 0.0003186635545324934\n",
      "name: input_transformers.layer.10.attention.self.key.bias, lr: 0.0003186635545324934\n",
      "name: input_transformers.layer.10.attention.self.value.weight, lr: 0.0003186635545324934\n",
      "name: input_transformers.layer.10.attention.self.value.bias, lr: 0.0003186635545324934\n",
      "name: input_transformers.layer.10.attention.output.dense.weight, lr: 0.0003186635545324934\n",
      "name: input_transformers.layer.10.attention.output.dense.bias, lr: 0.0003186635545324934\n",
      "name: input_transformers.layer.10.attention.output.LayerNorm.weight, lr: 0.0003186635545324934\n",
      "name: input_transformers.layer.10.attention.output.LayerNorm.bias, lr: 0.0003186635545324934\n",
      "name: input_transformers.layer.10.intermediate.dense.weight, lr: 0.0003186635545324934\n",
      "name: input_transformers.layer.10.intermediate.dense.bias, lr: 0.0003186635545324934\n",
      "name: input_transformers.layer.10.output.dense.weight, lr: 0.0003186635545324934\n",
      "name: input_transformers.layer.10.output.dense.bias, lr: 0.0003186635545324934\n",
      "name: input_transformers.layer.10.output.LayerNorm.weight, lr: 0.0003186635545324934\n",
      "name: input_transformers.layer.10.output.LayerNorm.bias, lr: 0.0003186635545324934\n",
      "name: input_transformers.layer.11.attention.self.query.weight, lr: 0.00035407061614721485\n",
      "name: input_transformers.layer.11.attention.self.query.bias, lr: 0.00035407061614721485\n",
      "name: input_transformers.layer.11.attention.self.key.weight, lr: 0.00035407061614721485\n",
      "name: input_transformers.layer.11.attention.self.key.bias, lr: 0.00035407061614721485\n",
      "name: input_transformers.layer.11.attention.self.value.weight, lr: 0.00035407061614721485\n",
      "name: input_transformers.layer.11.attention.self.value.bias, lr: 0.00035407061614721485\n",
      "name: input_transformers.layer.11.attention.output.dense.weight, lr: 0.00035407061614721485\n",
      "name: input_transformers.layer.11.attention.output.dense.bias, lr: 0.00035407061614721485\n",
      "name: input_transformers.layer.11.attention.output.LayerNorm.weight, lr: 0.00035407061614721485\n",
      "name: input_transformers.layer.11.attention.output.LayerNorm.bias, lr: 0.00035407061614721485\n",
      "name: input_transformers.layer.11.intermediate.dense.weight, lr: 0.00035407061614721485\n",
      "name: input_transformers.layer.11.intermediate.dense.bias, lr: 0.00035407061614721485\n",
      "name: input_transformers.layer.11.output.dense.weight, lr: 0.00035407061614721485\n",
      "name: input_transformers.layer.11.output.dense.bias, lr: 0.00035407061614721485\n",
      "name: input_transformers.layer.11.output.LayerNorm.weight, lr: 0.00035407061614721485\n",
      "name: input_transformers.layer.11.output.LayerNorm.bias, lr: 0.00035407061614721485\n",
      "name: position_embeddings.weight, lr: 0.0003934117957191276\n",
      "name: LayerNorm.weight, lr: 0.0003934117957191276\n",
      "name: LayerNorm.bias, lr: 0.0003934117957191276\n",
      "name: output_down_proj.0.weight, lr: 0.0003934117957191276\n",
      "name: output_down_proj.0.bias, lr: 0.0003934117957191276\n",
      "name: output_down_proj.2.weight, lr: 0.0003934117957191276\n",
      "name: output_down_proj.2.bias, lr: 0.0003934117957191276\n",
      "\n",
      "\n",
      "======== Training starts now ========\n",
      "\n",
      "\n",
      "Epoch 0/30000 Training Loss: 0.9780895709991455\n",
      "Epoch 0/30000 Validation Loss: 0.9868269562721252\n",
      "Cleared directory to save new best model.\n",
      "============>Saving current best model with min_val_loss=0.9868269562721252<=============\n",
      "Epoch 1/30000 Training Loss: 0.9887175559997559\n",
      "Epoch 2/30000 Training Loss: 0.9831829071044922\n",
      "Epoch 3/30000 Training Loss: 0.9805882573127747\n",
      "Epoch 4/30000 Training Loss: 0.9687364101409912\n",
      "Epoch 5/30000 Training Loss: 0.9811208248138428\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_62602/754797905.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m train_loss, val_loss = TrainLoop(\n\u001b[0m\u001b[1;32m      6\u001b[0m                             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                             \u001b[0mdiffusion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiffusion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/diffusion-text-generation/model_arch/train.py\u001b[0m in \u001b[0;36mrun_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m         ):\n\u001b[1;32m    125\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mbatch_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/diffusion-text-generation/model_arch/train.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self, batch, cond)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/diffusion-text-generation/model_arch/train.py\u001b[0m in \u001b[0;36mforward_backward\u001b[0;34m(self, batch, cond)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m             \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {self.step}/{self.learning_steps} Training Loss: {np.mean(train_losses)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "schedule_sampler = create_named_schedule_sampler('uniform', diffusion)\n",
    "\n",
    "model.to(dist_util.dev())\n",
    "\n",
    "train_loss, val_loss = TrainLoop(\n",
    "                            model=model,\n",
    "                            diffusion=diffusion,\n",
    "                            data=data,\n",
    "                            batch_size=batch_size,\n",
    "                            microbatch=microbatch,\n",
    "                            lr=lr,\n",
    "                            ema_rate=ema_rate,\n",
    "                            schedule_sampler=schedule_sampler,\n",
    "                            weight_decay=weight_decay,\n",
    "                            epochs=epochs,\n",
    "                            eval_data=val,\n",
    "                            eval_interval=eval_interval,\n",
    "                            warm_up_steps=500,\n",
    "                            use_llrd=True,\n",
    "                            llrd_rate=0.9\n",
    "                        ).run_loop()\n",
    "\n",
    "dt = datetime.now().strftime(\"%m%d\")\n",
    "pickle.dump(model, open(f\"models/{dt}/final_model_df{diffusion_steps}.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063fa9c7-84c8-48bd-b368-318df3f0275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e2649f-12d5-4248-9de7-e647d242578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_names = []\n",
    "# for i, (name, param) in enumerate(model.named_parameters()):\n",
    "#     param_names.append(name)\n",
    "#     print(f'{i}: {name} {param.requires_grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2881734-9e97-4947-9b4b-4b4766248ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_fp = f'models/0308/model_best_epoch_23930_min_val_loss_0.02459999918937683.pkl'\n",
    "with open(best_model_fp, 'rb') as handle:\n",
    "    best_model = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9ad7e2-8b77-4cb1-b18b-64de7518214c",
   "metadata": {},
   "source": [
    "# Generating sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8bf049",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_2000 = SpacedDiffusion(\n",
    "    betas=get_named_beta_schedule(noise_schedule, 2000),\n",
    "    rescale_timesteps=rescale_timesteps,\n",
    "    predict_xstart=predict_xstart,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc3e232-af43-44f3-8acb-ec31f1b0bd99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e82b32-6aba-47fe-8daf-07dcaa4fc938",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_lst_source, word_lst_recover, word_lst_ref, inter_lst_recover = sampling(best_model, \n",
    "                                                           diffusion_2000, \n",
    "                                                           tokenizer, \n",
    "                                                           data_dir=regular_data_dir, \n",
    "                                                           batch_size=10, \n",
    "                                                           split='test_custom', \n",
    "                                                           seq_len=128, \n",
    "                                                           show_intermediate_results=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed69bc0-8481-4287-bd2b-2e3188d1ff22",
   "metadata": {},
   "source": [
    "Generating 20 sentences takes 5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7a4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lst_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9184761",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lst_recover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a81787a-cde2-40ea-ae5b-2d3c66e84c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
